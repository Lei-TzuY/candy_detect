"""
æ ‡æ³¨è´¨é‡æ£€æŸ¥å·¥å…·
è‡ªåŠ¨æ£€æµ‹å¯èƒ½å­˜åœ¨é—®é¢˜çš„æ ‡æ³¨
"""
import os
from pathlib import Path
import cv2
import numpy as np
from collections import defaultdict
import json

def load_yolo_annotation(label_path, img_width, img_height):
    """åŠ è½½ YOLO æ ¼å¼æ ‡æ³¨"""
    boxes = []
    if not os.path.exists(label_path):
        return boxes
    
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = int(parts[0])
                x_center = float(parts[1])
                y_center = float(parts[2])
                width = float(parts[3])
                height = float(parts[4])
                
                boxes.append({
                    'class_id': class_id,
                    'x_center': x_center,
                    'y_center': y_center,
                    'width': width,
                    'height': height,
                    'area': width * height
                })
    return boxes

def check_annotations(dataset_dir):
    """æ£€æŸ¥æ ‡æ³¨è´¨é‡"""
    
    dataset_path = Path(dataset_dir)
    images_dir = dataset_path / 'images'
    labels_dir = dataset_path / 'labels'
    
    if not images_dir.exists() or not labels_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {images_dir} æˆ– {labels_dir}")
        return
    
    print("=" * 70)
    print("ğŸ” æ ‡æ³¨è´¨é‡æ£€æŸ¥")
    print("=" * 70)
    print(f"\nğŸ“ æ•°æ®é›†: {dataset_dir}")
    
    issues = defaultdict(list)
    stats = {
        'total_images': 0,
        'total_boxes': 0,
        'images_with_issues': 0,
        'class_counts': defaultdict(int),
        'area_stats': []
    }
    
    image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))
    
    print(f"\nğŸ–¼ï¸  æ€»å›¾ç‰‡æ•°: {len(image_files)}")
    print("\næ­£åœ¨æ£€æŸ¥...")
    
    for idx, img_path in enumerate(image_files):
        if (idx + 1) % 100 == 0:
            print(f"   è¿›åº¦: {idx + 1}/{len(image_files)}")
        
        stats['total_images'] += 1
        
        # è¯»å–å›¾ç‰‡å°ºå¯¸
        img = cv2.imread(str(img_path))
        if img is None:
            issues['corrupted_images'].append(str(img_path))
            continue
        
        h, w = img.shape[:2]
        
        # è¯»å–æ ‡æ³¨
        label_path = labels_dir / (img_path.stem + '.txt')
        boxes = load_yolo_annotation(label_path, w, h)
        
        # æ£€æŸ¥ 1: æ— æ ‡æ³¨å›¾ç‰‡
        if len(boxes) == 0:
            issues['no_annotations'].append(str(img_path.name))
            continue
        
        stats['total_boxes'] += len(boxes)
        has_issue = False
        
        for box in boxes:
            stats['class_counts'][box['class_id']] += 1
            stats['area_stats'].append(box['area'])
            
            # æ£€æŸ¥ 2: è¾¹ç•Œæ¡†è¶…å‡ºå›¾åƒèŒƒå›´
            x_min = box['x_center'] - box['width'] / 2
            y_min = box['y_center'] - box['height'] / 2
            x_max = box['x_center'] + box['width'] / 2
            y_max = box['y_center'] + box['height'] / 2
            
            if x_min < 0 or y_min < 0 or x_max > 1 or y_max > 1:
                issues['out_of_bounds'].append({
                    'image': img_path.name,
                    'box': box
                })
                has_issue = True
            
            # æ£€æŸ¥ 3: è¾¹ç•Œæ¡†è¿‡å°ï¼ˆå¯èƒ½æ˜¯è¯¯æ ‡ï¼‰
            if box['area'] < 0.001:  # å°äº 0.1%
                issues['too_small'].append({
                    'image': img_path.name,
                    'box': box,
                    'area_percent': box['area'] * 100
                })
                has_issue = True
            
            # æ£€æŸ¥ 4: è¾¹ç•Œæ¡†è¿‡å¤§ï¼ˆå¯èƒ½æ˜¯è¯¯æ ‡ï¼‰
            if box['area'] > 0.8:  # å¤§äº 80%
                issues['too_large'].append({
                    'image': img_path.name,
                    'box': box,
                    'area_percent': box['area'] * 100
                })
                has_issue = True
            
            # æ£€æŸ¥ 5: é•¿å®½æ¯”å¼‚å¸¸
            aspect_ratio = box['width'] / box['height'] if box['height'] > 0 else 999
            if aspect_ratio > 5 or aspect_ratio < 0.2:
                issues['abnormal_aspect'].append({
                    'image': img_path.name,
                    'box': box,
                    'aspect_ratio': aspect_ratio
                })
                has_issue = True
        
        # æ£€æŸ¥ 6: å•å¼ å›¾ç‰‡æ ‡æ³¨è¿‡å¤šï¼ˆå¯èƒ½é‡å¤æ ‡æ³¨ï¼‰
        if len(boxes) > 5:
            issues['too_many_boxes'].append({
                'image': img_path.name,
                'count': len(boxes)
            })
            has_issue = True
        
        if has_issue:
            stats['images_with_issues'] += 1
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š ç»Ÿè®¡ç»“æœ")
    print("=" * 70)
    
    print(f"\nâœ… æ€»å›¾ç‰‡æ•°: {stats['total_images']}")
    print(f"âœ… æ€»æ ‡æ³¨æ¡†æ•°: {stats['total_boxes']}")
    print(f"âš ï¸  æœ‰é—®é¢˜çš„å›¾ç‰‡: {stats['images_with_issues']} ({stats['images_with_issues']/stats['total_images']*100:.1f}%)")
    
    print(f"\nğŸ“¦ ç±»åˆ«åˆ†å¸ƒ:")
    for class_id, count in sorted(stats['class_counts'].items()):
        class_name = 'normal' if class_id == 0 else 'abnormal'
        print(f"   {class_name} (class {class_id}): {count} ä¸ª ({count/stats['total_boxes']*100:.1f}%)")
    
    if stats['area_stats']:
        areas = np.array(stats['area_stats'])
        print(f"\nğŸ“ è¾¹ç•Œæ¡†é¢ç§¯ç»Ÿè®¡:")
        print(f"   å¹³å‡: {areas.mean()*100:.2f}%")
        print(f"   ä¸­ä½æ•°: {np.median(areas)*100:.2f}%")
        print(f"   æœ€å°: {areas.min()*100:.2f}%")
        print(f"   æœ€å¤§: {areas.max()*100:.2f}%")
    
    # é—®é¢˜è¯¦æƒ…
    print("\n" + "=" * 70)
    print("âš ï¸  å‘ç°çš„é—®é¢˜")
    print("=" * 70)
    
    total_issues = sum(len(v) for v in issues.values())
    if total_issues == 0:
        print("\nâœ… å¤ªå¥½äº†ï¼æ²¡æœ‰å‘ç°æ˜æ˜¾çš„æ ‡æ³¨é—®é¢˜ï¼")
        return
    
    if issues['no_annotations']:
        print(f"\nâŒ æ— æ ‡æ³¨å›¾ç‰‡ ({len(issues['no_annotations'])} å¼ ):")
        for img in issues['no_annotations'][:10]:
            print(f"   - {img}")
        if len(issues['no_annotations']) > 10:
            print(f"   ... è¿˜æœ‰ {len(issues['no_annotations']) - 10} å¼ ")
    
    if issues['out_of_bounds']:
        print(f"\nâŒ è¾¹ç•Œæ¡†è¶…å‡ºèŒƒå›´ ({len(issues['out_of_bounds'])} ä¸ª):")
        for item in issues['out_of_bounds'][:5]:
            print(f"   - {item['image']}: {item['box']}")
        if len(issues['out_of_bounds']) > 5:
            print(f"   ... è¿˜æœ‰ {len(issues['out_of_bounds']) - 5} ä¸ª")
    
    if issues['too_small']:
        print(f"\nâš ï¸  è¾¹ç•Œæ¡†è¿‡å° ({len(issues['too_small'])} ä¸ª):")
        for item in issues['too_small'][:5]:
            print(f"   - {item['image']}: é¢ç§¯ {item['area_percent']:.3f}%")
        if len(issues['too_small']) > 5:
            print(f"   ... è¿˜æœ‰ {len(issues['too_small']) - 5} ä¸ª")
    
    if issues['too_large']:
        print(f"\nâš ï¸  è¾¹ç•Œæ¡†è¿‡å¤§ ({len(issues['too_large'])} ä¸ª):")
        for item in issues['too_large'][:5]:
            print(f"   - {item['image']}: é¢ç§¯ {item['area_percent']:.1f}%")
        if len(issues['too_large']) > 5:
            print(f"   ... è¿˜æœ‰ {len(issues['too_large']) - 5} ä¸ª")
    
    if issues['abnormal_aspect']:
        print(f"\nâš ï¸  é•¿å®½æ¯”å¼‚å¸¸ ({len(issues['abnormal_aspect'])} ä¸ª):")
        for item in issues['abnormal_aspect'][:5]:
            print(f"   - {item['image']}: é•¿å®½æ¯” {item['aspect_ratio']:.2f}")
        if len(issues['abnormal_aspect']) > 5:
            print(f"   ... è¿˜æœ‰ {len(issues['abnormal_aspect']) - 5} ä¸ª")
    
    if issues['too_many_boxes']:
        print(f"\nâš ï¸  æ ‡æ³¨æ¡†è¿‡å¤š ({len(issues['too_many_boxes'])} å¼ ):")
        for item in issues['too_many_boxes'][:5]:
            print(f"   - {item['image']}: {item['count']} ä¸ªæ ‡æ³¨")
        if len(issues['too_many_boxes']) > 5:
            print(f"   ... è¿˜æœ‰ {len(issues['too_many_boxes']) - 5} å¼ ")
    
    if issues['corrupted_images']:
        print(f"\nâŒ æŸåçš„å›¾ç‰‡ ({len(issues['corrupted_images'])} å¼ ):")
        for img in issues['corrupted_images'][:5]:
            print(f"   - {img}")
    
    # ä¿å­˜é—®é¢˜åˆ—è¡¨
    output_file = 'annotation_quality_report.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'stats': stats,
            'issues': {k: v for k, v in issues.items()}
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    
    # å»ºè®®
    print("\n" + "=" * 70)
    print("ğŸ’¡ å»ºè®®")
    print("=" * 70)
    
    if len(issues['no_annotations']) > 10:
        print("\nâš ï¸  æœ‰è¾ƒå¤šæ— æ ‡æ³¨å›¾ç‰‡ï¼Œå»ºè®®:")
        print("   1. ç¡®è®¤è¿™äº›å›¾ç‰‡æ˜¯å¦åº”è¯¥æœ‰æ ‡æ³¨")
        print("   2. å¦‚æœä¸éœ€è¦ï¼Œå¯ä»¥åˆ é™¤è¿™äº›å›¾ç‰‡")
        print("   3. å¦‚æœéœ€è¦ï¼Œè¡¥å……æ ‡æ³¨")
    
    if len(issues['out_of_bounds']) > 0:
        print("\nâŒ æœ‰è¾¹ç•Œæ¡†è¶…å‡ºèŒƒå›´ï¼Œè¿™æ˜¯ä¸¥é‡é—®é¢˜ï¼")
        print("   å»ºè®®åœ¨æ ‡æ³¨ç³»ç»Ÿä¸­ä¿®æ­£è¿™äº›æ ‡æ³¨")
    
    if len(issues['too_small']) > 20:
        print("\nâš ï¸  æœ‰è¾ƒå¤šè¿‡å°çš„è¾¹ç•Œæ¡†ï¼Œå¯èƒ½æ˜¯:")
        print("   1. æ ‡æ³¨å·¥å…·è¯¯æ“ä½œ")
        print("   2. çœŸçš„æ˜¯å¾ˆå°çš„ç‰©ä½“ï¼ˆéœ€ç¡®è®¤ï¼‰")
    
    critical_issues = len(issues['out_of_bounds']) + len(issues['corrupted_images'])
    if critical_issues > 0:
        print(f"\nğŸš¨ å»ºè®®: å‘ç° {critical_issues} ä¸ªä¸¥é‡é—®é¢˜ï¼Œå»ºè®®ä¿®æ­£åå†è®­ç»ƒï¼")
    elif total_issues > 50:
        print(f"\nâš ï¸  å»ºè®®: å‘ç° {total_issues} ä¸ªæ½œåœ¨é—®é¢˜ï¼Œå»ºè®®æŠ½æŸ¥éƒ¨åˆ†åå†è®­ç»ƒã€‚")
    else:
        print(f"\nâœ… æ ‡æ³¨è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='æ£€æŸ¥ YOLO æ•°æ®é›†æ ‡æ³¨è´¨é‡')
    parser.add_argument('--dataset', type=str, 
                        default='datasets/candy_merged_20260116_154158',
                        help='æ•°æ®é›†ç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    check_annotations(args.dataset)
