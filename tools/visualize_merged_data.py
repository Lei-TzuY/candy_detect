"""
ä¸ºåˆå¹¶çš„è®­ç»ƒæ•°æ®ç”Ÿæˆå¯è§†åŒ–
"""
import cv2
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm


def load_yolo_annotations(label_file, img_width, img_height):
    """åŠ è½½YOLOæ ¼å¼æ ‡æ³¨å¹¶è½¬æ¢ä¸ºåƒç´ åæ ‡"""
    annotations = []
    
    if not label_file.exists():
        return annotations
    
    with open(label_file, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = int(parts[0])
                x_center = float(parts[1]) * img_width
                y_center = float(parts[2]) * img_height
                width = float(parts[3]) * img_width
                height = float(parts[4]) * img_height
                
                x1 = int(x_center - width / 2)
                y1 = int(y_center - height / 2)
                x2 = int(x_center + width / 2)
                y2 = int(y_center + height / 2)
                
                annotations.append({
                    'class_id': class_id,
                    'bbox': (x1, y1, x2, y2)
                })
    
    return annotations


def draw_annotations(image, annotations, class_names=['normal', 'abnormal']):
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ ‡æ³¨æ¡†"""
    colors = {
        0: (0, 255, 0),    # ç»¿è‰² - normal
        1: (0, 0, 255)     # çº¢è‰² - abnormal
    }
    
    for ann in annotations:
        class_id = ann['class_id']
        x1, y1, x2, y2 = ann['bbox']
        
        color = colors.get(class_id, (255, 255, 255))
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = class_names[class_id] if class_id < len(class_names) else f"class_{class_id}"
        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        
        # æ ‡ç­¾èƒŒæ™¯
        cv2.rectangle(image, 
                     (x1, y1 - label_size[1] - 10), 
                     (x1 + label_size[0] + 10, y1), 
                     color, -1)
        
        # æ ‡ç­¾æ–‡å­—
        cv2.putText(image, label, 
                   (x1 + 5, y1 - 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 
                   0.6, (255, 255, 255), 2)
    
    return image


def visualize_dataset(dataset_dir, max_images=None):
    """ä¸ºæ•°æ®é›†ç”Ÿæˆå¯è§†åŒ–"""
    dataset_dir = Path(dataset_dir)
    images_dir = dataset_dir / 'images'
    labels_dir = dataset_dir / 'labels'
    vis_dir = dataset_dir / 'visualizations'
    
    vis_dir.mkdir(exist_ok=True)
    
    print(f"ðŸ“ æ•°æ®é›†ç›®å½•: {dataset_dir}")
    print(f"ðŸ–¼ï¸  å›¾ç‰‡ç›®å½•: {images_dir}")
    print(f"ðŸ·ï¸  æ ‡ç­¾ç›®å½•: {labels_dir}")
    print(f"ðŸ“Š è¾“å‡ºç›®å½•: {vis_dir}")
    print("-" * 60)
    
    # èŽ·å–æ‰€æœ‰å›¾ç‰‡
    image_files = list(images_dir.glob('*.jpg')) + \
                  list(images_dir.glob('*.jpeg')) + \
                  list(images_dir.glob('*.png'))
    
    if max_images:
        image_files = image_files[:max_images]
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    stats = {
        'total': 0,
        'with_annotations': 0,
        'without_annotations': 0,
        'total_boxes': 0
    }
    
    for img_file in tqdm(image_files, desc="ç”Ÿæˆå¯è§†åŒ–"):
        try:
            # ä½¿ç”¨PILè¯»å–å›¾ç‰‡ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
            pil_img = Image.open(img_file)
            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            img_height, img_width = img.shape[:2]
            
            # è¯»å–æ ‡æ³¨
            label_file = labels_dir / f"{img_file.stem}.txt"
            annotations = load_yolo_annotations(label_file, img_width, img_height)
            
            stats['total'] += 1
            
            if annotations:
                stats['with_annotations'] += 1
                stats['total_boxes'] += len(annotations)
                
                # ç»˜åˆ¶æ ‡æ³¨
                img = draw_annotations(img, annotations)
            else:
                stats['without_annotations'] += 1
                
                # æ·»åŠ "æ— æ ‡æ³¨"æ°´å°
                cv2.putText(img, "No Annotations", 
                           (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 
                           1.0, (0, 0, 255), 2)
            
            # ä¿å­˜å¯è§†åŒ–å›¾ç‰‡ï¼ˆä½¿ç”¨PILæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
            output_file = vis_dir / f"{img_file.stem}_vis.jpg"
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_output = Image.fromarray(img_rgb)
            pil_output.save(output_file, 'JPEG', quality=95)
            
        except Exception as e:
            print(f"âš ï¸  å¤„ç†å¤±è´¥: {img_file.name} - {e}")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print("\n" + "=" * 60)
    print("âœ… å¯è§†åŒ–å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»å›¾ç‰‡æ•°: {stats['total']}")
    print(f"æœ‰æ ‡æ³¨: {stats['with_annotations']} ({stats['with_annotations']/stats['total']*100:.1f}%)")
    print(f"æ— æ ‡æ³¨: {stats['without_annotations']} ({stats['without_annotations']/stats['total']*100:.1f}%)")
    print(f"æ€»æ ‡æ³¨æ¡†: {stats['total_boxes']}")
    print(f"å¹³å‡æ¯å¼ : {stats['total_boxes']/stats['total']:.2f} ä¸ªæ¡†")
    print(f"\nðŸ“ å¯è§†åŒ–ç»“æžœ: {vis_dir}")
    
    return vis_dir


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¸ºåˆå¹¶çš„æ•°æ®é›†ç”Ÿæˆå¯è§†åŒ–")
    parser.add_argument("--dataset", "-d", required=True, help="æ•°æ®é›†ç›®å½•")
    parser.add_argument("--max", "-m", type=int, help="æœ€å¤§å¤„ç†å›¾ç‰‡æ•°ï¼ˆç”¨äºŽå¿«é€Ÿé¢„è§ˆï¼‰")
    parser.add_argument("--open", "-o", action="store_true", help="å®ŒæˆåŽæ‰“å¼€æ–‡ä»¶å¤¹")
    
    args = parser.parse_args()
    
    vis_dir = visualize_dataset(args.dataset, args.max)
    
    if args.open:
        import subprocess
        subprocess.run(['explorer', str(vis_dir)], shell=True)
