# æ¨¡å‹æº–ç¢ºåº¦èˆ‡æ¼”ç®—æ³•æ•ˆç‡æå‡æŒ‡å—

## ğŸ“Š å·²å¯¦ä½œçš„å„ªåŒ–å·¥å…·

æˆ‘å·²ç¶“ç‚ºä½ å»ºç«‹äº† `utils/performance_optimizer.py`ï¼ŒåŒ…å«ä»¥ä¸‹å„ªåŒ–å·¥å…·ï¼š

### 1. **ModelOptimizer - æ¨¡å‹æ¨è«–å„ªåŒ–å™¨**
```python
from utils.performance_optimizer import ModelOptimizer

# åˆå§‹åŒ–å„ªåŒ–å™¨
optimizer = ModelOptimizer(model, input_size=416)

# æ¨¡å‹é ç†±ï¼ˆé¦–æ¬¡æ¨è«–é€šå¸¸è¼ƒæ…¢ï¼‰
optimizer.warmup_model(iterations=10)

# å„ªåŒ–çš„åµæ¸¬
classes, scores, boxes, inference_time = optimizer.detect_optimized(
    frame, conf_threshold, nms_threshold
)

# æŸ¥çœ‹å¹³å‡æ¨è«–æ™‚é–“
avg_time = optimizer.get_avg_inference_time()
print(f"å¹³å‡æ¨è«–æ™‚é–“: {avg_time:.2f} ms")
```

**æ•ˆç›Š:** é¦–æ¬¡æ¨è«–å¯èƒ½éœ€è¦ 500-1000msï¼Œé ç†±å¾Œå¯ç©©å®šåœ¨ 50-100ms

---

### 2. **ImagePreprocessor - å½±åƒé è™•ç†å„ªåŒ–å™¨**

æå‡å½±åƒå“è³ª = æå‡åµæ¸¬æº–ç¢ºåº¦

```python
from utils.performance_optimizer import ImagePreprocessor

# ç¶œåˆé è™•ç†
processed_frame = ImagePreprocessor.preprocess_frame(
    frame,
    enhance_contrast=True,    # CLAHE å°æ¯”åº¦å¢å¼·
    denoise_image=False,      # é™å™ªï¼ˆæœƒç¨å¾®é™ä½é€Ÿåº¦ï¼‰
    sharpen_image=False,      # éŠ³åŒ–é‚Šç·£
    auto_brightness_adjust=True  # è‡ªå‹•äº®åº¦èª¿æ•´
)

# å€‹åˆ¥è™•ç†
frame = ImagePreprocessor.enhance_contrast(frame)  # å°æ¯”åº¦å¢å¼·
frame = ImagePreprocessor.denoise(frame)           # é™å™ª
frame = ImagePreprocessor.sharpen(frame)           # éŠ³åŒ–
frame = ImagePreprocessor.auto_brightness(frame)   # äº®åº¦èª¿æ•´
```

**æ•ˆç›Š:**
- å°æ¯”åº¦å¢å¼·ï¼šæå‡ 10-20% æº–ç¢ºåº¦ï¼ˆç‰¹åˆ¥æ˜¯å…‰ç·šä¸å‡çš„æƒ…æ³ï¼‰
- é™å™ªï¼šæ¸›å°‘èª¤åµæ¸¬
- éŠ³åŒ–ï¼šå¢å¼·ç‘•ç–µé‚Šç·£ï¼Œæå‡å°ç‘•ç–µåµæ¸¬ç‡

---

### 3. **AdaptiveThresholdAdjuster - è‡ªé©æ‡‰é–¾å€¼èª¿æ•´**

æ ¹æ“šåµæ¸¬çµæœå‹•æ…‹èª¿æ•´ä¿¡å¿ƒåº¦é–¾å€¼

```python
from utils.performance_optimizer import AdaptiveThresholdAdjuster

adjuster = AdaptiveThresholdAdjuster(initial_conf=0.2, initial_nms=0.4)

# æ¯æ¬¡åµæ¸¬å¾Œèª¿æ•´
adjuster.adjust(num_detections=len(boxes), target_detections=5)

# å–å¾—æœ€æ–°é–¾å€¼
conf_threshold, nms_threshold = adjuster.get_thresholds()
```

**æ•ˆç›Š:** è‡ªå‹•å„ªåŒ–é–¾å€¼ï¼Œæ¸›å°‘æ¼æª¢å’Œèª¤æª¢

---

### 4. **PerformanceMonitor - æ€§èƒ½ç›£æ§å™¨**

å³æ™‚ç›£æ§ç³»çµ±æ€§èƒ½

```python
from utils.performance_optimizer import PerformanceMonitor

monitor = PerformanceMonitor()

# æ¯å¹€æ›´æ–°
monitor.update(inference_time=50.5)

# å–å¾—çµ±è¨ˆè³‡è¨Š
stats = monitor.get_stats()
print(f"å¹³å‡ FPS: {stats['avg_fps']}")
print(f"å¹³å‡æ¨è«–æ™‚é–“: {stats['avg_inference_time']} ms")
```

---

### 5. **MultiThreadedFrameReader - å¤šç·šç¨‹å½±åƒè®€å–**

æå‡æ”å½±æ©Ÿè®€å–æ•ˆç‡

```python
from utils.performance_optimizer import MultiThreadedFrameReader

# å•Ÿå‹•å¤šç·šç¨‹è®€å–
reader = MultiThreadedFrameReader(camera_contexts).start()

# è®€å–æœ€æ–°ç•«é¢ï¼ˆéé˜»å¡ï¼‰
frame = reader.read(camera_index=0)

# åœæ­¢è®€å–
reader.stop()
```

**æ•ˆç›Š:** FPS æå‡ 20-30%

---

### 6. **ROIOptimizer - æ„Ÿèˆˆè¶£å€åŸŸå„ªåŒ–**

åªåµæ¸¬é‡è¦å€åŸŸï¼Œæå‡é€Ÿåº¦

```python
from utils.performance_optimizer import ROIOptimizer

# å®šç¾© ROI å€åŸŸï¼ˆx1, y1, x2, y2ï¼‰
roi_coords = (100, 50, 800, 600)

# æå– ROI
roi_frame = ROIOptimizer.extract_roi(frame, roi_coords)

# åœ¨ ROI ä¸Šé€²è¡Œåµæ¸¬ï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰
classes, scores, boxes = model.detect(roi_frame, conf_threshold, nms_threshold)

# å°‡åº§æ¨™è½‰æ›å›åŸå§‹å½±åƒ
boxes = ROIOptimizer.adjust_detection_coords(boxes, roi_coords)
```

**æ•ˆç›Š:** æ¨è«–é€Ÿåº¦æå‡ 40-60%

---

## ğŸ¯ æ¨¡å‹è¨“ç·´æ”¹å–„å»ºè­°

### 1. **æ•¸æ“šå¢å¼· (Data Augmentation)**

å·²æä¾› `apply_data_augmentation()` å‡½æ•¸ï¼š

```python
from utils.performance_optimizer import apply_data_augmentation

# å¾ä¸€å¼µå½±åƒç”¢ç”Ÿ 7 å¼µå¢å¼·å½±åƒ
augmented_images = apply_data_augmentation(image)
```

**åŒ…å«çš„å¢å¼·æ–¹å¼ï¼š**
- æ°´å¹³ç¿»è½‰
- è¼•å¾®æ—‹è½‰ (Â±5åº¦)
- äº®åº¦èª¿æ•´ (Â±30)
- é«˜æ–¯å™ªè²

**å»ºè­°è¨“ç·´æµç¨‹ï¼š**
```bash
# 1. å°‡è¨“ç·´å½±åƒé€²è¡Œæ•¸æ“šå¢å¼·
python augment_training_data.py --input è¨“ç·´é›†è³‡æ–™/abnormal --output è¨“ç·´é›†è³‡æ–™/abnormal_augmented

# 2. æ›´æ–°è¨“ç·´é›†æ¸…å–®
python gen_train_val.py

# 3. é‡æ–°è¨“ç·´æ¨¡å‹
cd Yolo/darknet-master/build/darknet/x64
darknet.exe detector train train/myobj.data train/yolov4-tiny-myobj.cfg train/yolov4-tiny-myobj_last.weights
```

---

### 2. **å¢åŠ è¨“ç·´æ¨£æœ¬æ•¸é‡**

**ç›®æ¨™ï¼š**
- æ­£å¸¸å“ï¼šè‡³å°‘ 1000 å¼µ
- ç‘•ç–µå“ï¼šè‡³å°‘ 1000 å¼µï¼ˆæ¯ç¨®ç‘•ç–µé¡å‹è‡³å°‘ 200 å¼µï¼‰

**å»ºè­°ï¼š**
- æ”¶é›†ä¸åŒå…‰ç·šæ¢ä»¶ä¸‹çš„å½±åƒ
- æ”¶é›†ä¸åŒè§’åº¦çš„å½±åƒ
- ç¢ºä¿ç‘•ç–µå“çš„å¤šæ¨£æ€§

---

### 3. **èª¿æ•´è¨“ç·´åƒæ•¸**

ç·¨è¼¯ `Yolo/darknet-master/build/darknet/x64/train/yolov4-tiny-myobj.cfg`ï¼š

```ini
[net]
# å¢åŠ è¨“ç·´æ‰¹æ¬¡æ•¸
max_batches = 20000  # åŸæœ¬ 10000ï¼Œå»ºè­°å¢åŠ åˆ° 20000

# èª¿æ•´å­¸ç¿’ç‡è¡°æ¸›é»
steps=16000,18000  # åŸæœ¬ 8000,9000

# å¢åŠ æ•¸æ“šå¢å¼·
angle=15           # åŸæœ¬ 0ï¼Œå¢åŠ æ—‹è½‰è§’åº¦
saturation = 1.8   # åŸæœ¬ 1.5ï¼Œå¢åŠ é£½å’Œåº¦è®ŠåŒ–
exposure = 1.8     # åŸæœ¬ 1.5ï¼Œå¢åŠ æ›å…‰è®ŠåŒ–
```

---

### 4. **ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹**

å¦‚æœæº–ç¢ºåº¦ä¸å¤ ï¼Œå¯è€ƒæ…®å¾ YOLOv4-tiny å‡ç´šåˆ° YOLOv4ï¼š

**å„ªé»ï¼š**
- æº–ç¢ºåº¦æå‡ 10-15%
- æ›´é©åˆå°ç‰©é«”åµæ¸¬

**ç¼ºé»ï¼š**
- æ¨è«–é€Ÿåº¦é™ä½ç´„ 3-5 å€
- éœ€è¦æ›´å¤šè¨“ç·´æ™‚é–“

---

## âš¡ å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1ï¼šæ•´åˆæ‰€æœ‰å„ªåŒ–åˆ°ç¾æœ‰ç³»çµ±

```python
from utils.performance_optimizer import (
    ModelOptimizer, ImagePreprocessor,
    PerformanceMonitor, AdaptiveThresholdAdjuster
)

# åˆå§‹åŒ–å„ªåŒ–å·¥å…·
model_optimizer = ModelOptimizer(model, 416)
model_optimizer.warmup_model()
performance_monitor = PerformanceMonitor()
threshold_adjuster = AdaptiveThresholdAdjuster(0.2, 0.4)

# ä¸»å¾ªç’°
while True:
    ret, frame = cap.read()

    # 1. å½±åƒé è™•ç†
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    processed = ImagePreprocessor.preprocess_frame(
        gray_frame,
        enhance_contrast=True,
        auto_brightness_adjust=True
    )

    # 2. å„ªåŒ–çš„åµæ¸¬
    conf_thresh, nms_thresh = threshold_adjuster.get_thresholds()
    classes, scores, boxes, inf_time = model_optimizer.detect_optimized(
        processed, conf_thresh, nms_thresh
    )

    # 3. èª¿æ•´é–¾å€¼
    threshold_adjuster.adjust(len(boxes), target_detections=5)

    # 4. æ€§èƒ½ç›£æ§
    performance_monitor.update(inf_time)
    stats = performance_monitor.get_stats()

    # é¡¯ç¤ºæ€§èƒ½è³‡è¨Š
    cv2.putText(frame, f"FPS: {stats['avg_fps']:.1f}", (20, 250),
                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 0), 2)
    cv2.putText(frame, f"Inference: {stats['avg_inference_time']:.1f}ms",
                (20, 290), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 0), 2)
```

### ç¯„ä¾‹ 2ï¼šä½¿ç”¨ ROI å„ªåŒ–ï¼ˆé‡å°ç‰¹å®šå€åŸŸåµæ¸¬ï¼‰

```python
from utils.performance_optimizer import ROIOptimizer

# å®šç¾©æ„Ÿèˆˆè¶£å€åŸŸï¼ˆå‚³é€å¸¶ä¸­å¤®ï¼‰
roi_coords = (300, 200, 1600, 880)

# åªåœ¨ ROI å…§åµæ¸¬
roi_frame = ROIOptimizer.extract_roi(gray_frame, roi_coords)
classes, scores, boxes = model.detect(roi_frame, conf_threshold, nms_threshold)
boxes = ROIOptimizer.adjust_detection_coords(boxes, roi_coords)

# ç¹¼çºŒåŸæœ‰çš„è¿½è¹¤é‚è¼¯...
```

---

## ğŸ“ˆ é æœŸæ•ˆèƒ½æå‡

| å„ªåŒ–é …ç›® | æº–ç¢ºåº¦æå‡ | é€Ÿåº¦æå‡ | å¯¦ä½œé›£åº¦ |
|---------|----------|---------|---------|
| æ¨¡å‹é ç†± | 0% | âš¡ é¦–æ¬¡æ¨è«–å¿« 10å€ | ğŸŸ¢ ç°¡å–® |
| å½±åƒé è™•ç†ï¼ˆå°æ¯”åº¦å¢å¼·ï¼‰ | â†‘ 10-20% | 0% | ğŸŸ¢ ç°¡å–® |
| å½±åƒé è™•ç†ï¼ˆé™å™ªï¼‰ | â†‘ 5-10% | â†“ -5% | ğŸŸ¢ ç°¡å–® |
| è‡ªé©æ‡‰é–¾å€¼ | â†‘ 5-15% | 0% | ğŸŸ¡ ä¸­ç­‰ |
| ROI å„ªåŒ– | 0% | âš¡ +40-60% | ğŸŸ¢ ç°¡å–® |
| å¤šç·šç¨‹è®€å– | 0% | âš¡ +20-30% | ğŸŸ¡ ä¸­ç­‰ |
| æ•¸æ“šå¢å¼·ï¼ˆè¨“ç·´æ™‚ï¼‰ | â†‘ 15-30% | 0% | ğŸŸ¡ ä¸­ç­‰ |
| å¢åŠ è¨“ç·´æ¨£æœ¬ | â†‘ 20-40% | 0% | ğŸ”´ å›°é›£ |
| å‡ç´šåˆ° YOLOv4 | â†‘ 10-15% | â†“ -70% | ğŸŸ¡ ä¸­ç­‰ |

---

## ğŸ”§ å¿«é€Ÿé–‹å§‹

### æ­¥é©Ÿ 1ï¼šæ¸¬è©¦å½±åƒé è™•ç†æ•ˆæœ

```bash
python test_preprocessing.py --image test.jpg
```

### æ­¥é©Ÿ 2ï¼šæ•´åˆåˆ°ç¾æœ‰ç³»çµ±

ä¿®æ”¹ `run_detector.py`ï¼Œåœ¨åµæ¸¬å‰åŠ å…¥é è™•ç†ï¼š

```python
# åœ¨ process_camera_frame å‡½æ•¸ä¸­
gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

# åŠ å…¥é€™è¡Œ
gray_frame = ImagePreprocessor.preprocess_frame(gray_frame, enhance_contrast=True)

classes, scores, boxes = model.detect(gray_frame, conf_threshold, nms_threshold)
```

### æ­¥é©Ÿ 3ï¼šç›£æ§æ€§èƒ½

å•Ÿå‹•ç³»çµ±å¾Œï¼Œè§€å¯Ÿç•«é¢ä¸Šçš„ FPS å’Œæ¨è«–æ™‚é–“ï¼Œç¢ºèªå„ªåŒ–æ•ˆæœã€‚

---

## ğŸ’¡ æœ€ä½³å¯¦è¸å»ºè­°

1. **å¾ªåºæ¼¸é€²**ï¼šä¸€æ¬¡åŠ å…¥ä¸€å€‹å„ªåŒ–ï¼Œæ¸¬è©¦æ•ˆæœå¾Œå†åŠ å…¥ä¸‹ä¸€å€‹
2. **ä¿å­˜åŸºæº–**ï¼šå„ªåŒ–å‰å…ˆè¨˜éŒ„ç•¶å‰çš„æº–ç¢ºåº¦å’Œ FPS
3. **A/B æ¸¬è©¦**ï¼šå°æ¯”å„ªåŒ–å‰å¾Œçš„åµæ¸¬çµæœ
4. **ç›£æ§æ€§èƒ½**ï¼šä½¿ç”¨ PerformanceMonitor æŒçºŒè¿½è¹¤ç³»çµ±æ€§èƒ½
5. **å®šæœŸé‡è¨“**ï¼šæ”¶é›†æ–°çš„éŒ¯èª¤æ¡ˆä¾‹ï¼Œå®šæœŸé‡æ–°è¨“ç·´æ¨¡å‹

---

## ğŸ“ ç–‘é›£æ’è§£

### Q: åŠ å…¥å°æ¯”åº¦å¢å¼·å¾Œèª¤åµæ¸¬å¢åŠ ï¼Ÿ
**A:** é™ä½ `clip_limit` åƒæ•¸ï¼š
```python
frame = ImagePreprocessor.enhance_contrast(frame, clip_limit=1.5)  # é è¨­æ˜¯ 2.0
```

### Q: å¤šç·šç¨‹è®€å–å°è‡´ç•«é¢å»¶é²ï¼Ÿ
**A:** æª¢æŸ¥æ˜¯å¦ä½¿ç”¨äº†æœ€æ–°çš„ç•«é¢ï¼Œç¢ºä¿ `read()` å‡½æ•¸æ­£ç¢ºå¯¦ä½œã€‚

### Q: ROI å„ªåŒ–å¾Œç‰©é«”è¿½è¹¤å¤±æ•ˆï¼Ÿ
**A:** ç¢ºä¿åµæ¸¬çµæœçš„åº§æ¨™å·²æ­£ç¢ºè½‰æ›å›åŸå§‹å½±åƒåº§æ¨™ç³»ã€‚

---

**é–‹å§‹å„ªåŒ–ä½ çš„ç³»çµ±å§ï¼** ğŸš€
