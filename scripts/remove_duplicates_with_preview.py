"""
Remove duplicate images with HTML preview report.
Generates a visual report showing duplicates side-by-side before deletion.
"""
import os
import hashlib
from pathlib import Path
from PIL import Image
import imagehash
import base64
from io import BytesIO
import webbrowser
import send2trash
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# åŸ·è¡Œç·’å®‰å…¨çš„é€²åº¦è¨ˆæ•¸å™¨
_progress_lock = threading.Lock()
_progress_count = 0

def get_image_hash(image_path, hash_size=8):
    """Generate perceptual hash for an image."""
    try:
        with Image.open(image_path) as img:
            return str(imagehash.average_hash(img, hash_size=hash_size))
    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return None

def _hash_worker(args):
    """Worker function for parallel hash calculation."""
    img_path, hash_size = args
    img_hash = get_image_hash(img_path, hash_size)
    return (img_path, img_hash)

def image_to_base64(image_path, max_size=300):
    """Convert image to base64 for HTML embedding."""
    try:
        with Image.open(image_path) as img:
            # Resize for preview
            img.thumbnail((max_size, max_size))
            buffered = BytesIO()
            img.save(buffered, format="JPEG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            return f"data:image/jpeg;base64,{img_str}"
    except Exception as e:
        return None

def find_duplicates(directory, similarity_threshold=5):
    """
    Find duplicate images and return detailed information (æ”¯æ´å­è³‡æ–™å¤¾).
    
    Returns:
        tuple: (duplicate_groups, stats)
        duplicate_groups: list of dicts with 'original' and 'duplicates'
        stats: dictionary with statistics
    """
    directory = Path(directory)
    
    # Dictionary to store hash -> list of file paths
    hash_dict = {}
    
    # éè¿´æœå°‹æ‰€æœ‰å­è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    image_files = []
    for ext in image_extensions:
        image_files.extend(directory.rglob(f'*{ext}'))
    
    image_files = sorted(image_files)
    total_files = len(image_files)
    
    print(f"Found {total_files} image files in {directory}")
    print("Calculating image hashes... (using parallel processing)")
    
    # ä½¿ç”¨ ThreadPoolExecutor å¹³è¡Œè¨ˆç®— hashï¼ˆé è¨­ 8 å€‹åŸ·è¡Œç·’ï¼‰
    num_workers = min(8, max(1, total_files // 10))  # æ¯ 10 å¼µè‡³å°‘ 1 å€‹ worker
    processed = 0
    
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = {executor.submit(_hash_worker, (img_path, 8)): img_path for img_path in image_files}
        
        for future in as_completed(futures):
            img_path, img_hash = future.result()
            processed += 1
            
            if processed % 200 == 0 or processed == total_files:
                print(f"Processed {processed}/{total_files} images... ({processed*100//total_files}%)")
            
            if img_hash:
                if img_hash not in hash_dict:
                    hash_dict[img_hash] = []
                hash_dict[img_hash].append(img_path)
    
    # Find exact duplicates
    duplicate_groups = []
    all_duplicates = set()
    
    print("\nFinding exact duplicates...")
    for img_hash, paths in hash_dict.items():
        if len(paths) > 1:
            duplicate_groups.append({
                'original': paths[0],
                'duplicates': paths[1:],
                'reason': 'Exact duplicate (identical hash)',
                'hash_distance': 0
            })
            all_duplicates.update(paths[1:])
    
    # Find near-duplicates
    if similarity_threshold > 0:
        print("Finding near-duplicates...")
        hashes_list = list(hash_dict.keys())
        checked_pairs = set()
        
        for i in range(len(hashes_list)):
            if i % 100 == 0 and i > 0:
                print(f"Compared {i}/{len(hashes_list)} hash groups...")
            
            for j in range(i + 1, len(hashes_list)):
                pair_key = tuple(sorted([hashes_list[i], hashes_list[j]]))
                if pair_key in checked_pairs:
                    continue
                checked_pairs.add(pair_key)
                
                hash1 = imagehash.hex_to_hash(hashes_list[i])
                hash2 = imagehash.hex_to_hash(hashes_list[j])
                distance = hash1 - hash2
                
                if 0 < distance <= similarity_threshold:
                    # Similar images found
                    paths1 = hash_dict[hashes_list[i]]
                    paths2 = hash_dict[hashes_list[j]]
                    
                    # Use the first file from the first group as original
                    original = paths1[0]
                    duplicates = paths1[1:] + paths2
                    
                    # Remove duplicates that were already marked
                    new_duplicates = [p for p in duplicates if p not in all_duplicates]
                    
                    if new_duplicates:
                        duplicate_groups.append({
                            'original': original,
                            'duplicates': new_duplicates,
                            'reason': f'Near duplicate (difference: {distance})',
                            'hash_distance': distance
                        })
                        all_duplicates.update(new_duplicates)
    
    # Calculate statistics
    total_duplicates = len(all_duplicates)
    space_saved = sum(p.stat().st_size for p in all_duplicates)
    
    stats = {
        'total_files': len(image_files),
        'unique_files': len(image_files) - total_duplicates,
        'duplicate_groups': len(duplicate_groups),
        'total_duplicates': total_duplicates,
        'space_saved_mb': space_saved / 1024 / 1024
    }
    
    return duplicate_groups, stats

def generate_html_report(duplicate_groups, stats, output_file='duplicate_report.html', images_dir=None):
    """Generate HTML report with image previews.
    
    Args:
        duplicate_groups: é‡è¤‡ç¾¤çµ„åˆ—è¡¨
        stats: çµ±è¨ˆæ•¸æ“š
        output_file: è¼¸å‡ºæª”å
        images_dir: åœ–ç‰‡æ ¹ç›®éŒ„ï¼ˆç”¨æ–¼è¨ˆç®—ç›¸å°è·¯å¾‘ï¼‰
    """
    print(f"\nGenerating HTML report: {output_file}")
    
    html = f"""
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é‡è¤‡åœ–ç‰‡æª¢æ¸¬å ±å‘Š</title>
    <style>
        body {{
            font-family: "Microsoft JhengHei", Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background: #f5f5f5;
        }}
        .header {{
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-top: 15px;
        }}
        .stat-box {{
            background: #f0f7ff;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #2196F3;
        }}
        .stat-label {{
            font-size: 0.9em;
            color: #666;
        }}
        .stat-value {{
            font-size: 1.8em;
            font-weight: bold;
            color: #2196F3;
        }}
        .duplicate-group {{
            background: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .group-header {{
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }}
        .reason {{
            color: #666;
            font-size: 0.9em;
        }}
        .image-container {{
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            align-items: flex-start;
        }}
        .image-box {{
            flex: 0 0 auto;
            text-align: center;
            position: relative;
            transition: opacity 0.3s;
        }}
        .image-box.original {{
            border: 3px solid #4CAF50;
            padding: 10px;
            border-radius: 8px;
            background: #f1f8f4;
        }}
        .image-box.duplicate {{
            border: 3px solid #f44336;
            padding: 10px;
            border-radius: 8px;
            background: #fef1f0;
        }}
        .image-box img {{
            max-width: 250px;
            max-height: 250px;
            border-radius: 4px;
            display: block;
        }}
        .image-label {{
            margin-top: 8px;
            font-size: 0.85em;
            word-break: break-all;
            max-width: 250px;
        }}
        .badge {{
            display: inline-block;
            padding: 4px 8px;
            border-radius: 3px;
            font-size: 0.75em;
            font-weight: bold;
            margin-bottom: 5px;
        }}
        .badge.original {{
            background: #4CAF50;
            color: white;
        }}
        .badge.duplicate {{
            background: #f44336;
            color: white;
        }}
        .arrow {{
            font-size: 2em;
            color: #999;
            align-self: center;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ” é‡è¤‡åœ–ç‰‡æª¢æ¸¬å ±å‘Š</h1>
        <div class="stats">
            <div class="stat-box">
                <div class="stat-label">ç¸½åœ–ç‰‡æ•¸</div>
                <div class="stat-value">{stats['total_files']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">å”¯ä¸€åœ–ç‰‡</div>
                <div class="stat-value">{stats['unique_files']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">é‡è¤‡ç¾¤çµ„</div>
                <div class="stat-value">{stats['duplicate_groups']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">é‡è¤‡åœ–ç‰‡</div>
                <div class="stat-value">{stats['total_duplicates']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">å¯ç¯€çœç©ºé–“</div>
                <div class="stat-value">{stats['space_saved_mb']:.1f} MB</div>
            </div>
        </div>
        <p style="margin-top: 15px; color: #666;">
            âœ… <strong>ç¶ æ¡†</strong> = å°‡ä¿ç•™çš„åŸå§‹åœ–ç‰‡ | 
            âŒ <strong>ç´…æ¡†</strong> = å¯åˆªé™¤çš„é‡è¤‡åœ–ç‰‡ï¼ˆè«‹å‹¾é¸ï¼‰
        </p>
        <div style="margin-top: 15px;">
            <button id="selectAllBtn" onclick="toggleSelectAll()" style="padding: 10px 20px; margin-right: 10px; background: #2196F3; color: white; border: none; border-radius: 5px; cursor: pointer; font-size: 14px;">â˜‘ å…¨é¸</button>
            <button id="deleteSelectedBtn" onclick="deleteSelected()" style="padding: 10px 20px; background: #f44336; color: white; border: none; border-radius: 5px; cursor: pointer; font-size: 14px;">ğŸ—‘ï¸ åˆªé™¤é¸ä¸­é …</button>
            <span id="selectedCount" style="margin-left: 15px; color: #666;">å·²é¸æ“‡: 0</span>
        </div>
    </div>
"""
    
    # Add duplicate groups (é¡¯ç¤ºæ‰€æœ‰ç¾¤çµ„)
    for idx, group in enumerate(duplicate_groups, 1):
        original = group['original']
        duplicates = group['duplicates']
        reason = group['reason']
        
        html += f"""
    <div class="duplicate-group">
        <div class="group-header">
            <h3>é‡è¤‡ç¾¤çµ„ #{idx}</h3>
            <div class="reason">{reason}</div>
        </div>
        <div class="image-container">
            <div class="image-box original">
                <div class="badge original">ä¿ç•™</div>
"""
        
        # Add original image
        img_data = image_to_base64(original)
        if img_data:
            html += f'                <img src="{img_data}" alt="Original">\n'
        html += f'                <div class="image-label">ğŸ“ {original.name}</div>\n'
        html += '            </div>\n'
        
        html += '            <div class="arrow">â†’</div>\n'
        
        # Add duplicate images (é¡¯ç¤ºæ‰€æœ‰é‡è¤‡åœ–ç‰‡)
        for dup in duplicates:
            # è¨ˆç®—ç›¸å°è·¯å¾‘
            if images_dir:
                try:
                    dup_rel_path = str(dup.relative_to(images_dir)).replace('\\', '/')
                except ValueError:
                    dup_rel_path = dup.name
            else:
                dup_rel_path = dup.name
                
            html += f"""
            <div class="image-box duplicate" data-filename="{dup_rel_path}">
                <input type="checkbox" class="img-checkbox" style="position: absolute; top: 5px; left: 5px; width: 20px; height: 20px; cursor: pointer; z-index: 10;" onchange="updateSelectedCount()">
                <div class="badge duplicate" style="margin-left: 30px;">å¯åˆªé™¤</div>
"""
            img_data = image_to_base64(dup)
            if img_data:
                html += f'                <img src="{img_data}" alt="Duplicate">\n'
            html += f'                <div class="image-label">ğŸ“ {dup.name}</div>\n'
            html += '            </div>\n'
        
        html += '        </div>\n    </div>\n'
    
    html += """
    <script>
        let allSelected = false;
        
        function updateSelectedCount() {
            const checkboxes = document.querySelectorAll('.img-checkbox:checked');
            document.getElementById('selectedCount').textContent = `å·²é¸æ“‡: ${checkboxes.length}`;
        }
        
        function toggleSelectAll() {
            const checkboxes = document.querySelectorAll('.img-checkbox');
            allSelected = !allSelected;
            checkboxes.forEach(cb => cb.checked = allSelected);
            document.getElementById('selectAllBtn').textContent = allSelected ? 'â˜’ å–æ¶ˆå…¨é¸' : 'â˜‘ å…¨é¸';
            updateSelectedCount();
        }
        
        function deleteSelected() {
            const checkboxes = document.querySelectorAll('.img-checkbox:checked');
            if (checkboxes.length === 0) {
                alert('è«‹å…ˆå‹¾é¸è¦åˆªé™¤çš„åœ–ç‰‡');
                return;
            }
            
            const filenames = Array.from(checkboxes).map(cb => 
                cb.closest('.image-box').getAttribute('data-filename')
            );
            
            if (!confirm(`ç¢ºå®šè¦åˆªé™¤ ${filenames.length} å¼µåœ–ç‰‡å—ï¼Ÿ`)) {
                return;
            }
            
            // èª¿è©¦ä¿¡æ¯
            console.log('window.opener:', window.opener);
            console.log('deleteImagesFromReport:', window.opener ? window.opener.deleteImagesFromReport : 'N/A');
            
            // å˜—è©¦èª¿ç”¨çˆ¶çª—å£çš„åˆªé™¤å‡½æ•¸
            if (window.opener && typeof window.opener.deleteImagesFromReport === 'function') {
                window.opener.deleteImagesFromReport(filenames);
                alert('åˆªé™¤è«‹æ±‚å·²ç™¼é€ï¼');
                // Mark as deleted in UI
                checkboxes.forEach(cb => {
                    const box = cb.closest('.image-box');
                    box.style.opacity = '0.3';
                    box.querySelector('.badge').textContent = 'å·²åˆªé™¤';
                    box.querySelector('.badge').style.background = '#999';
                    cb.disabled = true;
                });
                updateSelectedCount();
            } else {
                // å¦‚æœç„¡æ³•é€šé window.openerï¼Œå˜—è©¦ç›´æ¥ API èª¿ç”¨
                console.error('ç„¡æ³•è¨ªå• window.opener.deleteImagesFromReport');
                
                if (confirm('ç„¡æ³•é€£æ¥åˆ°ä¸»è¦–çª—ã€‚è¦ç›´æ¥åˆªé™¤é€™äº›æ–‡ä»¶å—ï¼Ÿ')) {
                    deleteViaAPI(filenames, checkboxes);
                }
            }
        }
        
        async function deleteViaAPI(filenames, checkboxes) {
            try {
                // å¦‚æœæ˜¯ file:// å”è­°ï¼Œéœ€è¦ä½¿ç”¨å®Œæ•´ URL
                const baseUrl = window.location.protocol === 'file:' 
                    ? 'http://localhost:5000' 
                    : '';
                    
                const response = await fetch(baseUrl + '/api/annotate/delete-images', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ filenames: filenames })
                });
                
                const data = await response.json();
                
                if (response.ok) {
                    alert(`åˆªé™¤å®Œæˆï¼\\næˆåŠŸåˆªé™¤: ${data.deleted} å¼µåœ–ç‰‡`);
                    // Mark as deleted in UI
                    checkboxes.forEach(cb => {
                        const box = cb.closest('.image-box');
                        box.style.opacity = '0.3';
                        box.querySelector('.badge').textContent = 'å·²åˆªé™¤';
                        box.querySelector('.badge').style.background = '#999';
                        cb.disabled = true;
                    });
                    updateSelectedCount();
                } else {
                    alert('åˆªé™¤å¤±æ•—: ' + (data.error || 'æœªçŸ¥éŒ¯èª¤'));
                }
            } catch (error) {
                console.error('åˆªé™¤éŒ¯èª¤:', error);
                alert('åˆªé™¤å¤±æ•—: ' + error.message);
            }
        }
    </script>
</body>
</html>
"""
    
    # Write HTML file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"âœ… HTML å ±å‘Šå·²ç”Ÿæˆ: {output_file}")
    return output_file

def delete_duplicates(duplicate_groups):
    """Delete duplicate files."""
    all_duplicates = []
    for group in duplicate_groups:
        all_duplicates.extend(group['duplicates'])
    
    deleted = 0
    errors = 0
    
    for dup_path in all_duplicates:
        try:
            # dup_path.unlink()
            send2trash.send2trash(str(dup_path))
            deleted += 1
        except Exception as e:
            print(f"Error deleting {dup_path}: {e}")
            errors += 1
    
    return deleted, errors

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Remove duplicate images with visual preview')
    parser.add_argument('directory', nargs='?', 
                       default='datasets/extracted_frames',
                       help='Directory containing images')
    parser.add_argument('--threshold', type=int, default=5,
                       help='Similarity threshold (0-64, default=5)')
    parser.add_argument('--report', type=str, default='duplicate_report.html',
                       help='HTML report filename')
    parser.add_argument('--delete', action='store_true',
                       help='Delete duplicates after generating report')
    parser.add_argument('--no-browser', action='store_true',
                       help='Do not open browser automatically')
    
    args = parser.parse_args()
    
    # Check if directory exists
    if not os.path.exists(args.directory):
        print(f"Error: Directory '{args.directory}' not found!")
        exit(1)
    
    # Find duplicates
    duplicate_groups, stats = find_duplicates(args.directory, args.threshold)
    
    # Print statistics
    print(f"\n{'='*60}")
    print(f"æª¢æ¸¬çµæœ:")
    print(f"{'='*60}")
    print(f"ç¸½åœ–ç‰‡æ•¸: {stats['total_files']}")
    print(f"å”¯ä¸€åœ–ç‰‡: {stats['unique_files']}")
    print(f"é‡è¤‡ç¾¤çµ„: {stats['duplicate_groups']}")
    print(f"é‡è¤‡åœ–ç‰‡: {stats['total_duplicates']}")
    print(f"å¯ç¯€çœç©ºé–“: {stats['space_saved_mb']:.2f} MB")
    
    if stats['total_duplicates'] == 0:
        print("\nâœ… æ²’æœ‰æ‰¾åˆ°é‡è¤‡çš„åœ–ç‰‡ï¼")
        exit(0)
    
    # Generate HTML report
    report_path = generate_html_report(duplicate_groups, stats, args.report)
    
    # Open in browser
    if not args.no_browser:
        print(f"\nğŸŒ åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿå ±å‘Š...")
        webbrowser.open(f'file://{os.path.abspath(report_path)}')
    
    # Delete if requested
    if args.delete:
        print(f"\n{'='*60}")
        response = input(f"â“ ç¢ºèªè¦åˆªé™¤ {stats['total_duplicates']} å€‹é‡è¤‡æª”æ¡ˆå—? (yes/no): ")
        if response.lower() == 'yes':
            print("ğŸ—‘ï¸  æ­£åœ¨åˆªé™¤é‡è¤‡æª”æ¡ˆ...")
            deleted, errors = delete_duplicates(duplicate_groups)
            print(f"âœ… æˆåŠŸåˆªé™¤ {deleted} å€‹æª”æ¡ˆ")
            if errors > 0:
                print(f"âš ï¸  {errors} å€‹æª”æ¡ˆåˆªé™¤å¤±æ•—")
        else:
            print("âŒ å–æ¶ˆåˆªé™¤")
    else:
        print(f"\n{'='*60}")
        print("â„¹ï¸  é€™æ˜¯é è¦½æ¨¡å¼ï¼Œæ²’æœ‰åˆªé™¤ä»»ä½•æª”æ¡ˆ")
        print("   å¦‚æœç¢ºèªè¦åˆªé™¤ï¼Œè«‹åŸ·è¡Œ:")
        print(f"   python {os.path.basename(__file__)} --delete")
