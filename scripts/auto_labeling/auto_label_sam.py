"""
ä½¿ç”¨ SAM (Segment Anything Model) è¿›è¡Œè‡ªåŠ¨æ ‡æ³¨
SAM å¯ä»¥è‡ªåŠ¨æ£€æµ‹å›¾ç‰‡ä¸­çš„æ‰€æœ‰ç‰©ä½“ï¼Œæ— éœ€é¢„è®­ç»ƒ
"""
import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
import torch

def auto_label_with_sam(
    input_dir,
    output_dir=None,
    conf_threshold=0.7,
    min_area=1000,
    save_visualizations=True
):
    """
    ä½¿ç”¨ SAM è‡ªåŠ¨æ ‡æ³¨å›¾ç‰‡ä¸­çš„ç‰©ä½“
    
    Args:
        input_dir: è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹
        output_dir: è¾“å‡ºæ–‡ä»¶å¤¹
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        min_area: æœ€å°ç‰©ä½“é¢ç§¯ï¼ˆåƒç´ ï¼‰
        save_visualizations: æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
    """
    try:
        from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
    except ImportError:
        print("âŒ æœªå®‰è£… segment-anything åº“")
        print("è¯·è¿è¡Œ: pip install segment-anything")
        print("æˆ–: pip install git+https://github.com/facebookresearch/segment-anything.git")
        return
    
    input_path = Path(input_dir)
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = input_path.parent / f"{input_path.name}_sam_labeled_{timestamp}"
    else:
        output_dir = Path(output_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    labels_dir = output_dir / "labels"
    images_dir = output_dir / "images"
    vis_dir = output_dir / "visualizations" if save_visualizations else None
    
    labels_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)
    if vis_dir:
        vis_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½ SAM æ¨¡å‹
    print("ğŸ“¥ åŠ è½½ SAM æ¨¡å‹...")
    print("   (é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œçº¦ 2.4 GB)")
    
    # å°è¯•åŠ è½½ SAM æ¨¡å‹
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"   ä½¿ç”¨è®¾å¤‡: {device.upper()}")
    
    # è‡ªåŠ¨ä¸‹è½½ SAM checkpoint
    sam_checkpoint = "sam_vit_h_4b8939.pth"
    if not Path(sam_checkpoint).exists():
        print("   æ­£åœ¨ä¸‹è½½ SAM æ¨¡å‹...")
        import urllib.request
        url = "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
        urllib.request.urlretrieve(url, sam_checkpoint)
    
    sam = sam_model_registry["vit_h"](checkpoint=sam_checkpoint)
    sam.to(device=device)
    
    # åˆ›å»ºè‡ªåŠ¨æ ‡æ³¨ç”Ÿæˆå™¨
    mask_generator = SamAutomaticMaskGenerator(
        model=sam,
        points_per_side=32,
        pred_iou_thresh=conf_threshold,
        stability_score_thresh=0.9,
        crop_n_layers=1,
        crop_n_points_downscale_factor=2,
        min_mask_region_area=min_area,
    )
    
    # è·å–æ‰€æœ‰å›¾ç‰‡
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    image_files = [f for f in input_path.iterdir() 
                   if f.suffix.lower() in image_extensions]
    
    if not image_files:
        print(f"åœ¨ {input_dir} ä¸­æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
        return
    
    print(f"\næ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("-" * 60)
    
    # ç»Ÿè®¡
    total_detections = 0
    images_with_detections = 0
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    for img_file in tqdm(image_files, desc="å¤„ç†å›¾ç‰‡"):
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(str(img_file))
        if img is None:
            print(f"æ— æ³•è¯»å–: {img_file}")
            continue
        
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w = img.shape[:2]
        
        # ä½¿ç”¨ SAM ç”Ÿæˆ masks
        masks = mask_generator.generate(img_rgb)
        
        # æŒ‰é¢ç§¯æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„ç‰©ä½“
        masks = sorted(masks, key=lambda x: x['area'], reverse=True)
        
        # ä¿å­˜æ ‡æ³¨
        detections = []
        for mask_data in masks[:5]:  # æœ€å¤šå–å‰5ä¸ªæœ€å¤§çš„ç‰©ä½“
            mask = mask_data['segmentation']
            
            # è·å–è¾¹ç•Œæ¡†
            y_indices, x_indices = np.where(mask)
            if len(x_indices) == 0 or len(y_indices) == 0:
                continue
            
            x1, x2 = x_indices.min(), x_indices.max()
            y1, y2 = y_indices.min(), y_indices.max()
            
            # è½¬æ¢ä¸º YOLO æ ¼å¼
            x_center = ((x1 + x2) / 2) / w
            y_center = ((y1 + y2) / 2) / h
            width = (x2 - x1) / w
            height = (y2 - y1) / h
            
            # ç±»åˆ« 1 = abnormal
            detections.append([1, x_center, y_center, width, height])
            
            # å¯è§†åŒ–
            if save_visualizations:
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
                cv2.putText(img, "abnormal", (x1, y1 - 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # ä¿å­˜æ ‡æ³¨æ–‡ä»¶
        label_file = labels_dir / f"{img_file.stem}.txt"
        with open(label_file, 'w') as f:
            for det in detections:
                f.write(f"{det[0]} {det[1]:.6f} {det[2]:.6f} {det[3]:.6f} {det[4]:.6f}\n")
        
        # å¤åˆ¶å›¾ç‰‡
        import shutil
        shutil.copy2(img_file, images_dir / img_file.name)
        
        # ä¿å­˜å¯è§†åŒ–
        if save_visualizations and detections:
            cv2.imwrite(str(vis_dir / img_file.name), img)
        
        # ç»Ÿè®¡
        if detections:
            total_detections += len(detections)
            images_with_detections += 1
    
    # ç”Ÿæˆæ–‡ä»¶
    classes_file = output_dir / "classes.txt"
    with open(classes_file, 'w', encoding='utf-8') as f:
        f.write("normal\n")
        f.write("abnormal\n")
    
    yaml_file = output_dir / "dataset.yaml"
    with open(yaml_file, 'w', encoding='utf-8') as f:
        f.write(f"# SAM Auto-labeled - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"path: {output_dir.absolute()}\n")
        f.write("train: images\n")
        f.write("val: images\n\n")
        f.write("names:\n")
        f.write("  0: normal\n")
        f.write("  1: abnormal\n\n")
        f.write("nc: 2\n")
    
    # æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("SAM æ ‡æ³¨å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»å›¾ç‰‡æ•°: {len(image_files)}")
    print(f"æœ‰æ£€æµ‹ç»“æœçš„å›¾ç‰‡: {images_with_detections}")
    print(f"æ€»æ£€æµ‹æ¡†æ•°: {total_detections}")
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡: {total_detections/len(image_files):.2f}")
    print(f"\nè¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="SAM è‡ªåŠ¨æ ‡æ³¨")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹")
    parser.add_argument("--output", "-o", default=None, help="è¾“å‡ºæ–‡ä»¶å¤¹")
    parser.add_argument("--conf", "-c", type=float, default=0.7, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--min-area", type=int, default=1000, help="æœ€å°ç‰©ä½“é¢ç§¯")
    parser.add_argument("--no-vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–")
    
    args = parser.parse_args()
    
    auto_label_with_sam(
        input_dir=args.input,
        output_dir=args.output,
        conf_threshold=args.conf,
        min_area=args.min_area,
        save_visualizations=not args.no_vis
    )
