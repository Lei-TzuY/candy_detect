"""
ä½¿ç”¨ä¼ ç»Ÿè®¡ç®—æœºè§†è§‰æ–¹æ³•è‡ªåŠ¨æ ‡æ³¨ç³–æœ
åŸºäºé¢œè‰²ã€è½®å»“æ£€æµ‹ï¼Œæ— éœ€æ·±åº¦å­¦ä¹ æ¨¡å‹
"""
import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
import shutil


def find_candy_contours(img, min_area=500, max_area=50000):
    """
    ä½¿ç”¨è½®å»“æ£€æµ‹æ‰¾åˆ°ç³–æœ
    """
    # è½¬æ¢ä¸ºç°åº¦
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # é«˜æ–¯æ¨¡ç³Šå»å™ª
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # ä½¿ç”¨å¤šç§é˜ˆå€¼æ–¹æ³•
    detections = []
    
    # æ–¹æ³•1: è‡ªé€‚åº”é˜ˆå€¼
    adaptive = cv2.adaptiveThreshold(
        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # æ–¹æ³•2: Otsu é˜ˆå€¼
    _, otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    
    # æ–¹æ³•3: Canny è¾¹ç¼˜æ£€æµ‹
    edges = cv2.Canny(blurred, 50, 150)
    
    # ç»„åˆå¤šç§æ–¹æ³•
    combined = cv2.bitwise_or(adaptive, otsu)
    combined = cv2.bitwise_or(combined, edges)
    
    # å½¢æ€å­¦æ“ä½œï¼šé—­è¿ç®—å¡«è¡¥ç©ºéš™
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    closed = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel, iterations=2)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # ç­›é€‰è½®å»“
    valid_boxes = []
    for contour in contours:
        area = cv2.contourArea(contour)
        if min_area < area < max_area:
            x, y, w, h = cv2.boundingRect(contour)
            
            # è¿‡æ»¤æ‰å¤ªçª„æˆ–å¤ªæ‰çš„æ¡†
            aspect_ratio = w / h if h > 0 else 0
            if 0.3 < aspect_ratio < 3.0:
                valid_boxes.append((x, y, w, h, area))
    
    # æŒ‰é¢ç§¯æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„å‡ ä¸ª
    valid_boxes.sort(key=lambda x: x[4], reverse=True)
    
    return valid_boxes


def find_candy_by_color(img, min_area=500):
    """
    åŸºäºé¢œè‰²æ£€æµ‹ç³–æœ
    """
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # å®šä¹‰å¤šä¸ªé¢œè‰²èŒƒå›´ï¼ˆé€‚åº”ä¸åŒé¢œè‰²çš„ç³–æœï¼‰
    color_ranges = [
        # çº¢è‰² (ä¸¤ä¸ªèŒƒå›´ï¼Œå› ä¸ºçº¢è‰²è·¨è¶Š 0 åº¦)
        ([0, 50, 50], [10, 255, 255]),
        ([170, 50, 50], [180, 255, 255]),
        # é»„è‰²
        ([15, 50, 50], [35, 255, 255]),
        # ç»¿è‰²
        ([35, 50, 50], [85, 255, 255]),
        # è“è‰²
        ([85, 50, 50], [135, 255, 255]),
        # ç²‰è‰²/ç´«è‰²
        ([135, 50, 50], [170, 255, 255]),
    ]
    
    # ç»„åˆæ‰€æœ‰é¢œè‰²çš„ mask
    combined_mask = np.zeros(img.shape[:2], dtype=np.uint8)
    for lower, upper in color_ranges:
        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
        combined_mask = cv2.bitwise_or(combined_mask, mask)
    
    # å½¢æ€å­¦æ“ä½œ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    valid_boxes = []
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > min_area:
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 0
            if 0.3 < aspect_ratio < 3.0:
                valid_boxes.append((x, y, w, h, area))
    
    valid_boxes.sort(key=lambda x: x[4], reverse=True)
    return valid_boxes


def auto_label_traditional_cv(
    input_dir,
    output_dir=None,
    min_area=500,
    max_area=50000,
    max_detections_per_image=3,
    save_visualizations=True
):
    """
    ä½¿ç”¨ä¼ ç»Ÿ CV æ–¹æ³•è‡ªåŠ¨æ ‡æ³¨
    """
    input_path = Path(input_dir)
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = input_path.parent / f"{input_path.name}_cv_labeled_{timestamp}"
    else:
        output_dir = Path(output_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    labels_dir = output_dir / "labels"
    images_dir = output_dir / "images"
    vis_dir = output_dir / "visualizations" if save_visualizations else None
    
    labels_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)
    if vis_dir:
        vis_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾ç‰‡
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    image_files = [f for f in input_path.iterdir() 
                   if f.suffix.lower() in image_extensions]
    
    if not image_files:
        print(f"åœ¨ {input_dir} ä¸­æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
        return
    
    print("ğŸ” ä½¿ç”¨ä¼ ç»Ÿ CV æ–¹æ³•è¿›è¡Œè‡ªåŠ¨æ ‡æ³¨")
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"æœ€å°ç‰©ä½“é¢ç§¯: {min_area} åƒç´ ")
    print(f"æœ€å¤§ç‰©ä½“é¢ç§¯: {max_area} åƒç´ ")
    print("-" * 60)
    
    # ç»Ÿè®¡
    total_detections = 0
    images_with_detections = 0
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    for img_file in tqdm(image_files, desc="å¤„ç†å›¾ç‰‡"):
        img = cv2.imread(str(img_file))
        if img is None:
            print(f"æ— æ³•è¯»å–: {img_file}")
            continue
        
        h, w = img.shape[:2]
        
        # æ–¹æ³•1: è½®å»“æ£€æµ‹
        boxes_contour = find_candy_contours(img, min_area, max_area)
        
        # æ–¹æ³•2: é¢œè‰²æ£€æµ‹
        boxes_color = find_candy_by_color(img, min_area)
        
        # åˆå¹¶ç»“æœï¼ˆå»é‡ï¼‰
        all_boxes = boxes_contour + boxes_color
        
        # éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰å»é™¤é‡å çš„æ¡†
        final_boxes = nms_boxes(all_boxes, iou_threshold=0.5)
        
        # é™åˆ¶æ¯å¼ å›¾ç‰‡çš„æ£€æµ‹æ•°é‡
        final_boxes = final_boxes[:max_detections_per_image]
        
        # è½¬æ¢ä¸º YOLO æ ¼å¼å¹¶ä¿å­˜
        detections = []
        for (x, y, box_w, box_h, _) in final_boxes:
            # YOLO æ ¼å¼ï¼šä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜ï¼ˆå½’ä¸€åŒ–ï¼‰
            x_center = (x + box_w / 2) / w
            y_center = (y + box_h / 2) / h
            width = box_w / w
            height = box_h / h
            
            # ç±»åˆ« 1 = abnormal
            detections.append([1, x_center, y_center, width, height])
            
            # å¯è§†åŒ–
            if save_visualizations:
                cv2.rectangle(img, (x, y), (x + box_w, y + box_h), (0, 0, 255), 2)
                cv2.putText(img, "abnormal", (x, y - 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # ä¿å­˜æ ‡æ³¨æ–‡ä»¶
        label_file = labels_dir / f"{img_file.stem}.txt"
        with open(label_file, 'w') as f:
            for det in detections:
                f.write(f"{det[0]} {det[1]:.6f} {det[2]:.6f} {det[3]:.6f} {det[4]:.6f}\n")
        
        # å¤åˆ¶å›¾ç‰‡
        shutil.copy2(img_file, images_dir / img_file.name)
        
        # ä¿å­˜å¯è§†åŒ–
        if save_visualizations and detections:
            cv2.imwrite(str(vis_dir / img_file.name), img)
        
        # ç»Ÿè®¡
        if detections:
            total_detections += len(detections)
            images_with_detections += 1
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶
    classes_file = output_dir / "classes.txt"
    with open(classes_file, 'w', encoding='utf-8') as f:
        f.write("normal\n")
        f.write("abnormal\n")
    
    yaml_file = output_dir / "dataset.yaml"
    with open(yaml_file, 'w', encoding='utf-8') as f:
        f.write(f"# Traditional CV Auto-labeled - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"path: {output_dir.absolute()}\n")
        f.write("train: images\n")
        f.write("val: images\n\n")
        f.write("names:\n")
        f.write("  0: normal\n")
        f.write("  1: abnormal\n\n")
        f.write("nc: 2\n")
    
    # ç”ŸæˆæŠ¥å‘Š
    report_file = output_dir / "labeling_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("ä¼ ç»Ÿ CV æ–¹æ³•è‡ªåŠ¨æ ‡æ³¨æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"è¾“å…¥ç›®å½•: {input_dir}\n")
        f.write(f"è¾“å‡ºç›®å½•: {output_dir}\n\n")
        f.write(f"æ€»å›¾ç‰‡æ•°: {len(image_files)}\n")
        f.write(f"æœ‰æ£€æµ‹ç»“æœçš„å›¾ç‰‡: {images_with_detections}\n")
        f.write(f"æ€»æ£€æµ‹æ¡†æ•°: {total_detections}\n")
        f.write(f"å¹³å‡æ¯å¼ å›¾ç‰‡: {total_detections/len(image_files):.2f}\n")
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("âœ… æ ‡æ³¨å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»å›¾ç‰‡æ•°: {len(image_files)}")
    print(f"æœ‰æ£€æµ‹ç»“æœçš„å›¾ç‰‡: {images_with_detections}")
    print(f"æ€»æ£€æµ‹æ¡†æ•°: {total_detections}")
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡: {total_detections/len(image_files):.2f}")
    print(f"\nè¾“å‡ºç›®å½•: {output_dir}")
    print(f"æŠ¥å‘Š: {report_file}")


def nms_boxes(boxes, iou_threshold=0.5):
    """
    éæå¤§å€¼æŠ‘åˆ¶ï¼Œå»é™¤é‡å çš„æ¡†
    """
    if not boxes:
        return []
    
    boxes_array = np.array([(x, y, x+w, y+h, area) for x, y, w, h, area in boxes])
    
    x1 = boxes_array[:, 0]
    y1 = boxes_array[:, 1]
    x2 = boxes_array[:, 2]
    y2 = boxes_array[:, 3]
    areas = boxes_array[:, 4]
    
    # æŒ‰é¢ç§¯æ’åº
    order = areas.argsort()[::-1]
    
    keep = []
    while len(order) > 0:
        i = order[0]
        keep.append(i)
        
        # è®¡ç®— IoU
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        
        # ä¿ç•™ IoU å°äºé˜ˆå€¼çš„æ¡†
        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]
    
    return [boxes[i] for i in keep]


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¼ ç»Ÿ CV æ–¹æ³•è‡ªåŠ¨æ ‡æ³¨")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹")
    parser.add_argument("--output", "-o", default=None, help="è¾“å‡ºæ–‡ä»¶å¤¹")
    parser.add_argument("--min-area", type=int, default=500, help="æœ€å°ç‰©ä½“é¢ç§¯")
    parser.add_argument("--max-area", type=int, default=50000, help="æœ€å¤§ç‰©ä½“é¢ç§¯")
    parser.add_argument("--max-det", type=int, default=3, help="æ¯å¼ å›¾ç‰‡æœ€å¤§æ£€æµ‹æ•°")
    parser.add_argument("--no-vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–")
    
    args = parser.parse_args()
    
    auto_label_traditional_cv(
        input_dir=args.input,
        output_dir=args.output,
        min_area=args.min_area,
        max_area=args.max_area,
        max_detections_per_image=args.max_det,
        save_visualizations=not args.no_vis
    )
