"""
ç³–æœç‘•ç–µåµæ¸¬ç³»çµ± - æ¨¡å‹æ•ˆèƒ½è©•ä¼°èˆ‡æ¯”è¼ƒ
è©•ä¼°æ‰€æœ‰ YOLO æ¨¡å‹ä¸¦ç”Ÿæˆå¯è¦–åŒ–å ±å‘Š
"""
import sys
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json
import time

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ¨¡å‹é…ç½®
MODELS = {
    'YOLOv11n': 'datasets/æœ€æ–°è³‡æ–™é›†/yolo11n.pt',
    'YOLOv11s': 'datasets/æœ€æ–°è³‡æ–™é›†/yolo11s.pt',
    'YOLOv11m': 'datasets/æœ€æ–°è³‡æ–™é›†/yolo11m.pt',
    'YOLOv8n': 'datasets/æœ€æ–°è³‡æ–™é›†/yolov8n.pt',
    'YOLOv8s': 'datasets/æœ€æ–°è³‡æ–™é›†/yolov8s.pt',
    'YOLOv8m': 'datasets/æœ€æ–°è³‡æ–™é›†/yolov8m.pt',
}

# æ¸¬è©¦é…ç½®
TEST_CONFIG = {
    'data': 'D:/å°ˆæ¡ˆ/candy/datasets/æœ€æ–°è³‡æ–™é›†/data.yaml',  # ä½¿ç”¨æ­£ç¢ºçš„è³‡æ–™é›†
    'imgsz': 640,
    'batch': 16,
    'device': 0,  # 0 = GPU, 'cpu' = CPU
    'conf': 0.6,  # ä¿¡å¿ƒåº¦é–¾å€¼
    'iou': 0.45,  # NMS IoU é–¾å€¼
}

class ModelBenchmark:
    """æ¨¡å‹è©•ä¼°é¡åˆ¥"""
    
    def __init__(self, output_dir='reports/model_benchmark'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.results = []
        
    def benchmark_single_model(self, model_name, model_path):
        """è©•ä¼°å–®ä¸€æ¨¡å‹"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š è©•ä¼°æ¨¡å‹: {model_name}")
        print(f"{'='*60}")
        
        try:
            from ultralytics import YOLO
            
            # è¼‰å…¥æ¨¡å‹
            print(f"è¼‰å…¥æ¨¡å‹: {model_path}")
            model = YOLO(model_path)
            
            # åŸ·è¡Œé©—è­‰
            print("åŸ·è¡Œé©—è­‰æ¸¬è©¦...")
            start_time = time.time()
            
            val_results = model.val(
                data=TEST_CONFIG['data'],
                imgsz=TEST_CONFIG['imgsz'],
                batch=TEST_CONFIG['batch'],
                device=TEST_CONFIG['device'],
                conf=TEST_CONFIG['conf'],
                iou=TEST_CONFIG['iou'],
                plots=False,
                verbose=False
            )
            
            inference_time = time.time() - start_time
            
            # ç²å–æ¨¡å‹è³‡è¨Š
            model_info = model.info(verbose=False)
            
            # æå–æŒ‡æ¨™
            result = {
                'Model': model_name,
                'mAP50': float(val_results.box.map50),
                'mAP50-95': float(val_results.box.map),
                'Precision': float(val_results.box.mp),
                'Recall': float(val_results.box.mr),
                'F1-Score': float(2 * val_results.box.mp * val_results.box.mr / (val_results.box.mp + val_results.box.mr + 1e-6)),
                'Inference Speed (ms)': float(val_results.speed['inference']),
                'Parameters (M)': model_info[1] / 1e6 if isinstance(model_info, tuple) else 0,
                'FLOPs (G)': model_info[2] / 1e9 if isinstance(model_info, tuple) and len(model_info) > 2 else 0,
                'Model Size (MB)': Path(model_path).stat().st_size / (1024 * 1024),
                'Total Time (s)': inference_time
            }
            
            # é¡¯ç¤ºçµæœ
            print(f"âœ… å®Œæˆè©•ä¼°")
            print(f"  mAP50: {result['mAP50']:.3f}")
            print(f"  mAP50-95: {result['mAP50-95']:.3f}")
            print(f"  Precision: {result['Precision']:.3f}")
            print(f"  Recall: {result['Recall']:.3f}")
            print(f"  F1-Score: {result['F1-Score']:.3f}")
            print(f"  é€Ÿåº¦: {result['Inference Speed (ms)']:.2f} ms")
            print(f"  åƒæ•¸é‡: {result['Parameters (M)']:.2f} M")
            
            self.results.append(result)
            return result
            
        except Exception as e:
            print(f"âŒ è©•ä¼°å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_all_benchmarks(self):
        """åŸ·è¡Œæ‰€æœ‰æ¨¡å‹çš„è©•ä¼°"""
        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹æ¨¡å‹è©•ä¼° - ç³–æœç‘•ç–µåµæ¸¬ç³»çµ±")
        print("="*60)
        
        for model_name, model_path in MODELS.items():
            if not Path(model_path).exists():
                print(f"âš ï¸  è·³é {model_name}: æ‰¾ä¸åˆ°æª”æ¡ˆ {model_path}")
                continue
            
            self.benchmark_single_model(model_name, model_path)
        
        if not self.results:
            print("\nâŒ æ²’æœ‰æˆåŠŸè©•ä¼°ä»»ä½•æ¨¡å‹")
            return None
        
        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(self.results)
        df = df.sort_values('mAP50-95', ascending=False)
        
        return df
    
    def generate_visualizations(self, df):
        """ç”Ÿæˆå¯è¦–åŒ–åœ–è¡¨"""
        print("\nğŸ“Š ç”Ÿæˆå¯è¦–åŒ–åœ–è¡¨...")
        
        # è¨­å®šæ¨£å¼
        sns.set_style("whitegrid")
        sns.set_palette("husl")
        
        # 1. æº–ç¢ºåº¦æ¯”è¼ƒ (mAP)
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('YOLO æ¨¡å‹æ•ˆèƒ½æ¯”è¼ƒ - ç³–æœç‘•ç–µåµæ¸¬', fontsize=16, fontweight='bold')
        
        # 1.1 mAP50 vs mAP50-95
        ax1 = axes[0, 0]
        x = range(len(df))
        width = 0.35
        ax1.bar([i - width/2 for i in x], df['mAP50'], width, label='mAP50', alpha=0.8)
        ax1.bar([i + width/2 for i in x], df['mAP50-95'], width, label='mAP50-95', alpha=0.8)
        ax1.set_xlabel('æ¨¡å‹', fontsize=12)
        ax1.set_ylabel('mAP åˆ†æ•¸', fontsize=12)
        ax1.set_title('æº–ç¢ºåº¦æ¯”è¼ƒ (mAP)', fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(df['Model'], rotation=45, ha='right')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 1.2 Precision vs Recall
        ax2 = axes[0, 1]
        x = range(len(df))
        ax2.bar([i - width/2 for i in x], df['Precision'], width, label='Precision', alpha=0.8, color='green')
        ax2.bar([i + width/2 for i in x], df['Recall'], width, label='Recall', alpha=0.8, color='orange')
        ax2.set_xlabel('æ¨¡å‹', fontsize=12)
        ax2.set_ylabel('åˆ†æ•¸', fontsize=12)
        ax2.set_title('Precision vs Recall', fontsize=14, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(df['Model'], rotation=45, ha='right')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 1.3 æ¨è«–é€Ÿåº¦
        ax3 = axes[1, 0]
        bars = ax3.barh(df['Model'], df['Inference Speed (ms)'], alpha=0.8, color='skyblue')
        ax3.set_xlabel('æ¨è«–æ™‚é–“ (ms)', fontsize=12)
        ax3.set_ylabel('æ¨¡å‹', fontsize=12)
        ax3.set_title('æ¨è«–é€Ÿåº¦æ¯”è¼ƒ (è¶Šä½è¶Šå¥½)', fontsize=14, fontweight='bold')
        ax3.invert_yaxis()
        # åœ¨æ¢å½¢ä¸Šé¡¯ç¤ºæ•¸å€¼
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax3.text(width, bar.get_y() + bar.get_height()/2, 
                    f'{width:.2f}ms', ha='left', va='center', fontsize=10)
        ax3.grid(True, alpha=0.3, axis='x')
        
        # 1.4 æ¨¡å‹å¤§å° vs æº–ç¢ºåº¦
        ax4 = axes[1, 1]
        scatter = ax4.scatter(df['Parameters (M)'], df['mAP50-95'], 
                             s=df['Model Size (MB)']*10, alpha=0.6, c=range(len(df)), cmap='viridis')
        for idx, row in df.iterrows():
            ax4.annotate(row['Model'], (row['Parameters (M)'], row['mAP50-95']),
                        xytext=(5, 5), textcoords='offset points', fontsize=9)
        ax4.set_xlabel('åƒæ•¸é‡ (M)', fontsize=12)
        ax4.set_ylabel('mAP50-95', fontsize=12)
        ax4.set_title('æ¨¡å‹è¤‡é›œåº¦ vs æº–ç¢ºåº¦', fontsize=14, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # å„²å­˜åœ–è¡¨
        chart_path = self.output_dir / f'model_comparison_{self.timestamp}.png'
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        print(f"âœ… åœ–è¡¨å·²å„²å­˜: {chart_path}")
        plt.close()
        
        # 2. ç¶œåˆæ•ˆèƒ½é›·é”åœ–
        self._generate_radar_chart(df)
        
        # 3. F1-Score æ’å
        self._generate_f1_ranking(df)
        
        return chart_path
    
    def _generate_radar_chart(self, df):
        """ç”Ÿæˆé›·é”åœ–"""
        from math import pi
        
        # é¸æ“‡è¦é¡¯ç¤ºçš„æŒ‡æ¨™ï¼ˆæ¨™æº–åŒ–åˆ° 0-1ï¼‰
        metrics = ['mAP50-95', 'Precision', 'Recall', 'F1-Score']
        
        # è¨ˆç®—é€Ÿåº¦åˆ†æ•¸ (è¶Šå¿«åˆ†æ•¸è¶Šé«˜)
        max_speed = df['Inference Speed (ms)'].max()
        df['Speed Score'] = 1 - (df['Inference Speed (ms)'] / max_speed)
        metrics.append('Speed Score')
        
        fig = plt.figure(figsize=(14, 10))
        
        # ç‚ºæ¯å€‹æ¨¡å‹å‰µå»ºä¸€å€‹å­åœ–
        n_models = len(df)
        n_cols = 3
        n_rows = (n_models + n_cols - 1) // n_cols
        
        for idx, (_, row) in enumerate(df.iterrows()):
            ax = fig.add_subplot(n_rows, n_cols, idx + 1, projection='polar')
            
            values = [row[m] for m in metrics]
            values += values[:1]  # é–‰åˆåœ–å½¢
            
            angles = [n / float(len(metrics)) * 2 * pi for n in range(len(metrics))]
            angles += angles[:1]
            
            ax.plot(angles, values, 'o-', linewidth=2, label=row['Model'])
            ax.fill(angles, values, alpha=0.25)
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(metrics, fontsize=8)
            ax.set_ylim(0, 1)
            ax.set_title(row['Model'], fontsize=12, fontweight='bold', pad=20)
            ax.grid(True)
        
        plt.suptitle('æ¨¡å‹æ•ˆèƒ½é›·é”åœ–', fontsize=16, fontweight='bold', y=0.98)
        plt.tight_layout()
        
        radar_path = self.output_dir / f'radar_chart_{self.timestamp}.png'
        plt.savefig(radar_path, dpi=300, bbox_inches='tight')
        print(f"âœ… é›·é”åœ–å·²å„²å­˜: {radar_path}")
        plt.close()
    
    def _generate_f1_ranking(self, df):
        """ç”Ÿæˆ F1-Score æ’ååœ–"""
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # æ’åº
        df_sorted = df.sort_values('F1-Score', ascending=True)
        
        # ç¹ªè£½æ°´å¹³æ¢å½¢åœ–
        colors = plt.cm.RdYlGn(df_sorted['F1-Score'])
        bars = ax.barh(df_sorted['Model'], df_sorted['F1-Score'], color=colors, alpha=0.8)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width, bar.get_y() + bar.get_height()/2, 
                   f'{width:.3f}', ha='left', va='center', fontsize=11, fontweight='bold')
        
        ax.set_xlabel('F1-Score', fontsize=12, fontweight='bold')
        ax.set_ylabel('æ¨¡å‹', fontsize=12, fontweight='bold')
        ax.set_title('æ¨¡å‹ F1-Score æ’å', fontsize=14, fontweight='bold')
        ax.set_xlim(0, 1.0)
        ax.grid(True, alpha=0.3, axis='x')
        
        plt.tight_layout()
        
        f1_path = self.output_dir / f'f1_ranking_{self.timestamp}.png'
        plt.savefig(f1_path, dpi=300, bbox_inches='tight')
        print(f"âœ… F1-Score æ’åå·²å„²å­˜: {f1_path}")
        plt.close()
    
    def generate_html_report(self, df):
        """ç”Ÿæˆ HTML å ±å‘Š"""
        print("\nğŸ“„ ç”Ÿæˆ HTML å ±å‘Š...")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_map = df.loc[df['mAP50-95'].idxmax()]
        best_speed = df.loc[df['Inference Speed (ms)'].idxmin()]
        best_f1 = df.loc[df['F1-Score'].idxmax()]
        
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¨¡å‹æ•ˆèƒ½è©•ä¼°å ±å‘Š - ç³–æœç‘•ç–µåµæ¸¬ç³»çµ±</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: 'Microsoft JhengHei', 'Segoe UI', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.6;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
        }}
        .header p {{
            font-size: 1.2em;
            opacity: 0.9;
        }}
        .content {{
            padding: 40px;
        }}
        .summary {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}
        .summary-card {{
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-radius: 10px;
            padding: 25px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}
        .summary-card h3 {{
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
        }}
        .summary-card .model-name {{
            font-size: 1.5em;
            font-weight: bold;
            color: #333;
            margin: 10px 0;
        }}
        .summary-card .metric {{
            display: flex;
            justify-content: space-between;
            margin: 8px 0;
            padding: 8px;
            background: white;
            border-radius: 5px;
        }}
        .metric-label {{
            color: #666;
        }}
        .metric-value {{
            font-weight: bold;
            color: #333;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            border-radius: 10px;
            overflow: hidden;
        }}
        th {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: 600;
        }}
        td {{
            padding: 12px 15px;
            border-bottom: 1px solid #f0f0f0;
        }}
        tr:hover {{
            background-color: #f5f7fa;
        }}
        tr:last-child td {{
            border-bottom: none;
        }}
        .best-badge {{
            display: inline-block;
            background: #4CAF50;
            color: white;
            padding: 3px 10px;
            border-radius: 12px;
            font-size: 0.85em;
            margin-left: 10px;
        }}
        .images {{
            margin: 40px 0;
        }}
        .images img {{
            width: 100%;
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
            margin: 20px 0;
        }}
        .section-title {{
            font-size: 2em;
            color: #333;
            margin: 40px 0 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }}
        .recommendation {{
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 20px;
            margin: 30px 0;
            border-radius: 5px;
        }}
        .recommendation h3 {{
            color: #856404;
            margin-bottom: 15px;
        }}
        .recommendation ul {{
            margin-left: 20px;
        }}
        .recommendation li {{
            margin: 8px 0;
            color: #856404;
        }}
        .footer {{
            background: #f5f7fa;
            padding: 20px;
            text-align: center;
            color: #666;
            margin-top: 40px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¬ æ¨¡å‹æ•ˆèƒ½è©•ä¼°å ±å‘Š</h1>
            <p>ç³–æœç‘•ç–µåµæ¸¬ç³»çµ± - YOLO æ¨¡å‹æ¯”è¼ƒåˆ†æ</p>
            <p style="font-size: 0.9em; margin-top: 10px;">ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>
        </div>
        
        <div class="content">
            <h2 class="section-title">ğŸ“Š æœ€ä½³æ¨¡å‹æ‘˜è¦</h2>
            <div class="summary">
                <div class="summary-card">
                    <h3>ğŸ† æœ€é«˜æº–ç¢ºåº¦</h3>
                    <div class="model-name">{best_map['Model']}</div>
                    <div class="metric">
                        <span class="metric-label">mAP50-95:</span>
                        <span class="metric-value">{best_map['mAP50-95']:.3f}</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">mAP50:</span>
                        <span class="metric-value">{best_map['mAP50']:.3f}</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">Precision:</span>
                        <span class="metric-value">{best_map['Precision']:.3f}</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">Recall:</span>
                        <span class="metric-value">{best_map['Recall']:.3f}</span>
                    </div>
                </div>
                
                <div class="summary-card">
                    <h3>âš¡ æœ€å¿«é€Ÿåº¦</h3>
                    <div class="model-name">{best_speed['Model']}</div>
                    <div class="metric">
                        <span class="metric-label">æ¨è«–æ™‚é–“:</span>
                        <span class="metric-value">{best_speed['Inference Speed (ms)']:.2f} ms</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">mAP50-95:</span>
                        <span class="metric-value">{best_speed['mAP50-95']:.3f}</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">åƒæ•¸é‡:</span>
                        <span class="metric-value">{best_speed['Parameters (M)']:.2f} M</span>
                    </div>
                </div>
                
                <div class="summary-card">
                    <h3>âš–ï¸ æœ€ä½³å¹³è¡¡ (F1-Score)</h3>
                    <div class="model-name">{best_f1['Model']}</div>
                    <div class="metric">
                        <span class="metric-label">F1-Score:</span>
                        <span class="metric-value">{best_f1['F1-Score']:.3f}</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">æ¨è«–æ™‚é–“:</span>
                        <span class="metric-value">{best_f1['Inference Speed (ms)']:.2f} ms</span>
                    </div>
                    <div class="metric">
                        <span class="metric-label">mAP50-95:</span>
                        <span class="metric-value">{best_f1['mAP50-95']:.3f}</span>
                    </div>
                </div>
            </div>
            
            <h2 class="section-title">ğŸ“ˆ è©³ç´°æ•ˆèƒ½æ¯”è¼ƒ</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ’å</th>
                        <th>æ¨¡å‹</th>
                        <th>mAP50-95</th>
                        <th>mAP50</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1-Score</th>
                        <th>é€Ÿåº¦ (ms)</th>
                        <th>åƒæ•¸é‡ (M)</th>
                        <th>å¤§å° (MB)</th>
                    </tr>
                </thead>
                <tbody>
"""
        
        # æ·»åŠ è¡¨æ ¼è¡Œ
        for rank, (_, row) in enumerate(df.iterrows(), 1):
            best_tags = []
            if row['Model'] == best_map['Model']:
                best_tags.append('<span class="best-badge">æœ€é«˜æº–ç¢ºåº¦</span>')
            if row['Model'] == best_speed['Model']:
                best_tags.append('<span class="best-badge">æœ€å¿«é€Ÿåº¦</span>')
            if row['Model'] == best_f1['Model']:
                best_tags.append('<span class="best-badge">æœ€ä½³å¹³è¡¡</span>')
            
            html_content += f"""
                    <tr>
                        <td>{rank}</td>
                        <td><strong>{row['Model']}</strong>{''.join(best_tags)}</td>
                        <td>{row['mAP50-95']:.3f}</td>
                        <td>{row['mAP50']:.3f}</td>
                        <td>{row['Precision']:.3f}</td>
                        <td>{row['Recall']:.3f}</td>
                        <td>{row['F1-Score']:.3f}</td>
                        <td>{row['Inference Speed (ms)']:.2f}</td>
                        <td>{row['Parameters (M)']:.2f}</td>
                        <td>{row['Model Size (MB)']:.2f}</td>
                    </tr>
"""
        
        html_content += f"""
                </tbody>
            </table>
            
            <div class="recommendation">
                <h3>ğŸ’¡ é¸å‹å»ºè­°</h3>
                <ul>
                    <li><strong>é«˜æº–ç¢ºåº¦éœ€æ±‚:</strong> æ¨è–¦ä½¿ç”¨ <strong>{best_map['Model']}</strong>ï¼Œå…·æœ‰æœ€é«˜çš„ mAP50-95 ({best_map['mAP50-95']:.3f})ï¼Œé©åˆå“è³ªè¦æ±‚åš´æ ¼çš„å ´æ™¯</li>
                    <li><strong>é«˜é€Ÿåº¦éœ€æ±‚:</strong> æ¨è–¦ä½¿ç”¨ <strong>{best_speed['Model']}</strong>ï¼Œæ¨è«–æ™‚é–“åƒ… {best_speed['Inference Speed (ms)']:.2f} msï¼Œé©åˆé«˜é€Ÿç”Ÿç”¢ç·š</li>
                    <li><strong>å¹³è¡¡å‹éœ€æ±‚:</strong> æ¨è–¦ä½¿ç”¨ <strong>{best_f1['Model']}</strong>ï¼ŒF1-Score æœ€é«˜ ({best_f1['F1-Score']:.3f})ï¼Œæº–ç¢ºåº¦å’Œé€Ÿåº¦å…¼é¡§</li>
                    <li><strong>è³‡æºå—é™ç’°å¢ƒ:</strong> YOLOv8n/YOLOv11n ç³»åˆ—æ¨¡å‹åƒæ•¸é‡å°‘ã€é€Ÿåº¦å¿«ï¼Œé©åˆé‚Šç·£è¨­å‚™éƒ¨ç½²</li>
                </ul>
            </div>
            
            <h2 class="section-title">ğŸ“Š å¯è¦–åŒ–åœ–è¡¨</h2>
            <div class="images">
                <img src="model_comparison_{self.timestamp}.png" alt="æ¨¡å‹æ¯”è¼ƒåœ–è¡¨">
                <img src="radar_chart_{self.timestamp}.png" alt="é›·é”åœ–">
                <img src="f1_ranking_{self.timestamp}.png" alt="F1-Scoreæ’å">
            </div>
            
            <h2 class="section-title">ğŸ“ è©•ä¼°èªªæ˜</h2>
            <div style="background: #f5f7fa; padding: 20px; border-radius: 10px; margin: 20px 0;">
                <h4>æŒ‡æ¨™èªªæ˜:</h4>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li><strong>mAP50-95:</strong> åœ¨ IoU é–¾å€¼ 0.5-0.95 ç¯„åœå…§çš„å¹³å‡ç²¾åº¦ï¼Œç¶œåˆè©•ä¼°æ¨¡å‹æº–ç¢ºåº¦</li>
                    <li><strong>mAP50:</strong> IoU é–¾å€¼ç‚º 0.5 æ™‚çš„å¹³å‡ç²¾åº¦ï¼Œè¼ƒç‚ºå¯¬é¬†çš„æº–ç¢ºåº¦æŒ‡æ¨™</li>
                    <li><strong>Precision (ç²¾ç¢ºç‡):</strong> é æ¸¬ç‚ºé™½æ€§çš„æ¨£æœ¬ä¸­å¯¦éš›ç‚ºé™½æ€§çš„æ¯”ä¾‹</li>
                    <li><strong>Recall (å¬å›ç‡):</strong> å¯¦éš›ç‚ºé™½æ€§çš„æ¨£æœ¬ä¸­è¢«æ­£ç¢ºé æ¸¬ç‚ºé™½æ€§çš„æ¯”ä¾‹</li>
                    <li><strong>F1-Score:</strong> Precision å’Œ Recall çš„èª¿å’Œå¹³å‡æ•¸ï¼Œç¶œåˆè©•ä¼°æ¨¡å‹æ€§èƒ½</li>
                    <li><strong>æ¨è«–é€Ÿåº¦:</strong> å–®å¼µå½±åƒçš„è™•ç†æ™‚é–“ï¼Œè¶Šä½è¶Šå¥½</li>
                </ul>
                
                <h4 style="margin-top: 20px;">æ¸¬è©¦é…ç½®:</h4>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li>è³‡æ–™é›†: {TEST_CONFIG['data']}</li>
                    <li>å½±åƒå¤§å°: {TEST_CONFIG['imgsz']}Ã—{TEST_CONFIG['imgsz']}</li>
                    <li>æ‰¹æ¬¡å¤§å°: {TEST_CONFIG['batch']}</li>
                    <li>è£ç½®: {'GPU' if TEST_CONFIG['device'] == 0 else 'CPU'}</li>
                    <li>ä¿¡å¿ƒåº¦é–¾å€¼: {TEST_CONFIG['conf']}</li>
                    <li>NMS IoU é–¾å€¼: {TEST_CONFIG['iou']}</li>
                </ul>
            </div>
        </div>
        
        <div class="footer">
            <p>Â© 2026 ç³–æœç‘•ç–µåµæ¸¬ç³»çµ± | æ¨¡å‹æ•ˆèƒ½è©•ä¼°å ±å‘Š</p>
            <p style="margin-top: 5px; font-size: 0.9em;">å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
    </div>
</body>
</html>
"""
        
        # å„²å­˜ HTML
        html_path = self.output_dir / f'benchmark_report_{self.timestamp}.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… HTML å ±å‘Šå·²å„²å­˜: {html_path}")
        return html_path
    
    def save_results(self, df):
        """å„²å­˜çµæœåˆ° CSV å’Œ JSON"""
        # CSV
        csv_path = self.output_dir / f'benchmark_results_{self.timestamp}.csv'
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… CSV çµæœå·²å„²å­˜: {csv_path}")
        
        # JSON
        json_path = self.output_dir / f'benchmark_results_{self.timestamp}.json'
        results_dict = {
            'timestamp': self.timestamp,
            'test_config': TEST_CONFIG,
            'results': df.to_dict('records'),
            'summary': {
                'best_accuracy': df.loc[df['mAP50-95'].idxmax()].to_dict(),
                'best_speed': df.loc[df['Inference Speed (ms)'].idxmin()].to_dict(),
                'best_f1': df.loc[df['F1-Score'].idxmax()].to_dict(),
            }
        }
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, indent=2, ensure_ascii=False)
        print(f"âœ… JSON çµæœå·²å„²å­˜: {json_path}")
        
        return csv_path, json_path


def main():
    """ä¸»ç¨‹å¼"""
    print("\n" + "="*60)
    print("ğŸ¬ ç³–æœç‘•ç–µåµæ¸¬ç³»çµ± - æ¨¡å‹æ•ˆèƒ½è©•ä¼°")
    print("="*60 + "\n")
    
    # æª¢æŸ¥è³‡æ–™é›†é…ç½®æª”æ¡ˆ
    data_yaml = Path(TEST_CONFIG['data'])
    if not data_yaml.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™é›†é…ç½®æª”æ¡ˆ: {data_yaml}")
        print("è«‹ä¿®æ”¹ TEST_CONFIG['data'] æŒ‡å‘æ­£ç¢ºçš„ .yaml æª”æ¡ˆ")
        return
    
    # å‰µå»ºè©•ä¼°å™¨
    benchmark = ModelBenchmark()
    
    # åŸ·è¡Œè©•ä¼°
    df = benchmark.run_all_benchmarks()
    
    if df is None or len(df) == 0:
        print("\nâŒ è©•ä¼°å¤±æ•—æˆ–ç„¡å¯ç”¨æ¨¡å‹")
        return
    
    # ç”Ÿæˆå¯è¦–åŒ–
    benchmark.generate_visualizations(df)
    
    # ç”Ÿæˆ HTML å ±å‘Š
    html_path = benchmark.generate_html_report(df)
    
    # å„²å­˜çµæœ
    benchmark.save_results(df)
    
    # é¡¯ç¤ºæ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“Š è©•ä¼°å®Œæˆï¼æ‘˜è¦:")
    print("="*60)
    print(f"\næœ€ä½³æº–ç¢ºåº¦: {df.loc[df['mAP50-95'].idxmax()]['Model']} (mAP50-95: {df['mAP50-95'].max():.3f})")
    print(f"æœ€å¿«é€Ÿåº¦: {df.loc[df['Inference Speed (ms)'].idxmin()]['Model']} ({df['Inference Speed (ms)'].min():.2f} ms)")
    print(f"æœ€ä½³å¹³è¡¡: {df.loc[df['F1-Score'].idxmax()]['Model']} (F1: {df['F1-Score'].max():.3f})")
    
    print(f"\nğŸ“„ å®Œæ•´å ±å‘Š: {html_path}")
    print(f"ğŸ“Š åœ–è¡¨ä½ç½®: {benchmark.output_dir}")
    
    # è‡ªå‹•é–‹å•Ÿ HTML å ±å‘Š
    try:
        import webbrowser
        webbrowser.open(html_path.as_uri())
        print("\nâœ… å·²åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿå ±å‘Š")
    except:
        print("\nâš ï¸  è«‹æ‰‹å‹•é–‹å•Ÿ HTML å ±å‘Š")


if __name__ == '__main__':
    main()
